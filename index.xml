<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Introduction on 笔记本</title>
    <link>https://ruichengm1987.github.io/</link>
    <description>Recent content in Introduction on 笔记本</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    
	<atom:link href="https://ruichengm1987.github.io/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>1.「图」的基本知识</title>
      <link>https://ruichengm1987.github.io/docs/algorithm/%E5%9B%BE/1.%E5%9B%BE%E7%9A%84%E5%9F%BA%E6%9C%AC%E7%9F%A5%E8%AF%86/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ruichengm1987.github.io/docs/algorithm/%E5%9B%BE/1.%E5%9B%BE%E7%9A%84%E5%9F%BA%E6%9C%AC%E7%9F%A5%E8%AF%86/</guid>
      <description>1.「图」的基本知识 「图」大概是最接近生活的一种数据结构了，生活中各种关系图便是「图」最真实的写照。比如，我们每个人的朋友交际圈就是一个巨大的「图」。  图1.小A的朋友交际图    「图」的类型 「图」的类型有很多,我们将介绍三种类型的图：无向图、有向图、加权图。
无向图 「无向图」的图中任意两个顶点之间的边都是没有方向的。 「图1. 小A的朋友交际图」是一个无向图。
有向图 「有向图」的图中任意两个顶点之间的边都是有方向的。 「图 2. 有向图的示例图」是一个有向图。  图2.有向图的示例图    加权图 「加权图」的图中的每条边都带有一个相关的权重。这里的权重可以是任何一种度量，比如时间，距离，尺寸等。生活中最常见的「加权图」应该就是我们的地图了。在下方的「图 3. 加权图的示例图」中，每条边上都标有距离，它们可以视为每个边上的权重。  图3.加权图的示例图    「图」的定义和相关术语 「图」是由顶点和边组成的一种非线形数据结构。在「图」中有很多相关术语来描述一个图。如果在后面的学习中遇到不认识的术语，请回到这里查看相关的定义。
 顶点：在「图 1. 小A的朋友交际图」中，小 A 、小 B 、小 C 等均称为「图」的顶点。 边：顶点之间的连接线称为边。在「图 1. 小A的朋友交际图」中，小 A 和小 B 之间的连接线就是图中的一条边。 路径：从一个顶点到另一个顶点之间经过的所有顶点的集合。在「图 1. 小A的朋友交际图」中，从小 A 到小 C 的路径为[小A, 小B, 小C] 或者[小A, 小G, 小B, 小C]或者[小A, 小E, 小F, 小D, 小B, 小C]。 **注意：**两个顶点之间的路径可以是很多条。 路径长度：一条路径上经过的边的数量。在「图 1.</description>
    </item>
    
    <item>
      <title>1.异步通信原理</title>
      <link>https://ruichengm1987.github.io/docs/kafka/1.%E5%BC%82%E6%AD%A5%E9%80%9A%E4%BF%A1%E5%8E%9F%E7%90%86/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ruichengm1987.github.io/docs/kafka/1.%E5%BC%82%E6%AD%A5%E9%80%9A%E4%BF%A1%E5%8E%9F%E7%90%86/</guid>
      <description>1.异步通信原理 观察者模式  观察者模式（Observer），又叫发布-订阅模式（Publish/Subscribe） 定义对象间一种一对多的依赖关系，使得每当一个对象改变状态，则所有依赖于它的对象都会得到 通知并自动更新。 一个对象（目标对象）的状态发生改变，所有的依赖对象（观察者对象）都将得到通知。   现实生活中的应用场景  京东到货通知    生产者消费者模式  传统模式  生产者直接将消息传递给指定的消费者 耦合性特别高，当生产者或者消费者发生变化，都需要重写业务逻辑   生产者消费者模式  通过一个容器来解决生产者和消费者的强耦合问题。生产者和消费者彼此之间不直接通讯，而通过阻塞队列来进行通讯     数据传递流程  生产者消费者模式，即N个线程进行生产，同时N个线程进行消费，两种角色通过内存缓冲区 进行通信， 生产者负责向缓冲区里面添加数据单元 消费者负责从缓冲区里面取出数据单元  一般遵循先进先出的原则      缓冲区  解耦  假设生产者和消费者分别是两个类。如果让生产者直接调用消费者的某个方法，那么生产者 对于消费者就会产生依赖   支持并发  生产者直接调用消费者的某个方法过程中函数调用是同步的 万一消费者处理数据很慢，生产者就会白白糟蹋大好时光    数据单元  关联到业务对象  数据单元必须关联到某种业务对象   完整性  就是在传输过程中，要保证该数据单元的完整   独立性  就是各个数据单元之间没有互相依赖 某个数据单元传输失败不应该影响已经完成传输的单元；也不应该影响尚未传输的单元。   颗粒度  数据单元需要关联到某种业务对象。那么数据单元和业务对象应该处于的关系（一对一？一 对多） 如果颗粒度过小会增加数据传输的次数 如果颗粒度过大会增加单个数据传输的时间，影响后期消费    </description>
    </item>
    
    <item>
      <title>2.1.Quick Find 的「并查集」</title>
      <link>https://ruichengm1987.github.io/docs/algorithm/%E5%9B%BE/2.%E5%B9%B6%E6%9F%A5%E9%9B%86/2.1.quick-find-%E7%9A%84%E5%B9%B6%E6%9F%A5%E9%9B%86/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ruichengm1987.github.io/docs/algorithm/%E5%9B%BE/2.%E5%B9%B6%E6%9F%A5%E9%9B%86/2.1.quick-find-%E7%9A%84%E5%B9%B6%E6%9F%A5%E9%9B%86/</guid>
      <description>2.1.Quick Find 的「并查集」 Quick Find的工作原理 //todo::
伪代码 (todo:://提供一版go的代码) // UnionFind.class public class UnionFind { int root[]; public UnionFind(int size) { root = new int[size]; for (int i = 0; i &amp;lt; size; i++) { root[i] = i; } } public int find(int x) { return root[x]; } public void union(int x, int y) { int rootX = find(x); int rootY = find(y); if (rootX != rootY) { for (int i = 0; i &amp;lt; root.</description>
    </item>
    
    <item>
      <title>3.1.深度优先搜索算法-遍历所有顶点</title>
      <link>https://ruichengm1987.github.io/docs/algorithm/%E5%9B%BE/3.%E5%9B%BE%E7%9A%84%E6%B7%B1%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2%E7%AE%97%E6%B3%95-/3.1.%E6%B7%B1%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2%E7%AE%97%E6%B3%95-%E9%81%8D%E5%8E%86%E6%89%80%E6%9C%89%E9%A1%B6%E7%82%B9/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ruichengm1987.github.io/docs/algorithm/%E5%9B%BE/3.%E5%9B%BE%E7%9A%84%E6%B7%B1%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2%E7%AE%97%E6%B3%95-/3.1.%E6%B7%B1%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2%E7%AE%97%E6%B3%95-%E9%81%8D%E5%8E%86%E6%89%80%E6%9C%89%E9%A1%B6%E7%82%B9/</guid>
      <description>3.1.深度优先搜索算法-遍历所有顶点 代码 时间复杂度 O(V+E)。
VV 表示顶点数，EE 表示边数。
空间复杂度 O(V)。
VV 表示顶点数。</description>
    </item>
    
    <item>
      <title>4.1.广度优先搜索算法-遍历所有顶点</title>
      <link>https://ruichengm1987.github.io/docs/algorithm/%E5%9B%BE/4.%E5%9B%BE%E7%9A%84%E5%B9%BF%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2%E7%AE%97%E6%B3%95/4.1.%E5%B9%BF%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2%E7%AE%97%E6%B3%95-%E9%81%8D%E5%8E%86%E6%89%80%E6%9C%89%E9%A1%B6%E7%82%B9/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ruichengm1987.github.io/docs/algorithm/%E5%9B%BE/4.%E5%9B%BE%E7%9A%84%E5%B9%BF%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2%E7%AE%97%E6%B3%95/4.1.%E5%B9%BF%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2%E7%AE%97%E6%B3%95-%E9%81%8D%E5%8E%86%E6%89%80%E6%9C%89%E9%A1%B6%E7%82%B9/</guid>
      <description>4.1.广度优先搜索算法-遍历所有顶点 代码 //todo::
时间复杂度 O(V+E)O(V+E)。
VV 表示顶点数，EE 表示边数。
空间复杂度 O(V)O(V)。</description>
    </item>
    
    <item>
      <title>4.2.广度优先搜索算法-求两点之间最短路径</title>
      <link>https://ruichengm1987.github.io/docs/algorithm/%E5%9B%BE/4.%E5%9B%BE%E7%9A%84%E5%B9%BF%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2%E7%AE%97%E6%B3%95/4.2.%E5%B9%BF%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2%E7%AE%97%E6%B3%95-%E6%B1%82%E4%B8%A4%E7%82%B9%E4%B9%8B%E9%97%B4%E6%9C%80%E7%9F%AD%E8%B7%AF%E5%BE%84/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ruichengm1987.github.io/docs/algorithm/%E5%9B%BE/4.%E5%9B%BE%E7%9A%84%E5%B9%BF%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2%E7%AE%97%E6%B3%95/4.2.%E5%B9%BF%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2%E7%AE%97%E6%B3%95-%E6%B1%82%E4%B8%A4%E7%82%B9%E4%B9%8B%E9%97%B4%E6%9C%80%E7%9F%AD%E8%B7%AF%E5%BE%84/</guid>
      <description>4.2.广度优先搜索算法-求两点之间最短路径 代码 //todo::
时间复杂度 O(V+E)O(V+E)。
VV 表示顶点数，EE 表示边数。
空间复杂度 O(V)O(V)。
VV 表示顶点数。</description>
    </item>
    
    <item>
      <title>冒泡排序</title>
      <link>https://ruichengm1987.github.io/docs/algorithm/%E6%8E%92%E5%BA%8F/on2/%E5%86%92%E6%B3%A1%E6%8E%92%E5%BA%8F/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ruichengm1987.github.io/docs/algorithm/%E6%8E%92%E5%BA%8F/on2/%E5%86%92%E6%B3%A1%E6%8E%92%E5%BA%8F/</guid>
      <description>冒泡排序 冒泡排序有三种写法：  一边比较一边向后两两交换，将最大值 / 最小值冒泡到最后一位； 经过优化的写法：使用一个变量记录当前轮次的比较是否发生过交换，如果没有发生交换表示已经有序，不再继续排序； 进一步优化的写法：除了使用变量记录当前轮次是否发生交换外，再使用一个变量记录上次发生交换的位置，下一轮排序时到达上次交换的位置就停止比较。  代码 package main import ( &amp;quot;fmt&amp;quot; ) func main() { values1 := []int{4, 93, 84, 85, 80, 37, 81, 93, 27, 12} fmt.Println(values1) // [4 93 84 85 80 37 81 93 27 12] MySort1(values1) fmt.Println(values1) // [4 12 27 37 80 81 84 85 93 93] values2 := []int{4, 93, 84, 85, 80, 37, 81, 93, 27, 12} fmt.Println(values2) // [4 93 84 85 80 37 81 93 27 12] MySort1(values2) fmt.</description>
    </item>
    
    <item>
      <title>配置网卡</title>
      <link>https://ruichengm1987.github.io/docs/vbox/%E9%85%8D%E7%BD%AE%E7%BD%91%E5%8D%A1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ruichengm1987.github.io/docs/vbox/%E9%85%8D%E7%BD%AE%E7%BD%91%E5%8D%A1/</guid>
      <description>配置网卡 https://blog.csdn.net/weixin_42541479/article/details/118407951
1、安装centos7的时候注意选择两个网卡 两个网卡分别为：
nat(虚拟机访问互联网，使用10.0.2.x段)
host-only(虚拟机和主机互相通信，使用192.168.56.x段)
在偏好设置里面设置网络。如下图配置：
    2、配置网络    3、开机，进入 cd /etc/etc/sysconfig/network-scripts/ 目录 cd /etc/sysconfig/network-scripts/ ls   vi ifcfg-enp0s3   vi ifcfg-enp0s8   service network restart   4、验证    拷贝 </description>
    </item>
    
    <item>
      <title>2.2.Quick Union 的「并查集」</title>
      <link>https://ruichengm1987.github.io/docs/algorithm/%E5%9B%BE/2.%E5%B9%B6%E6%9F%A5%E9%9B%86/2.2.quick-union-%E7%9A%84%E5%B9%B6%E6%9F%A5%E9%9B%86/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ruichengm1987.github.io/docs/algorithm/%E5%9B%BE/2.%E5%B9%B6%E6%9F%A5%E9%9B%86/2.2.quick-union-%E7%9A%84%E5%B9%B6%E6%9F%A5%E9%9B%86/</guid>
      <description>2.2.Quick Union 的「并查集」 Quick Union 工作原理 //todo::
为什么 Quick Union 比 Quick Find 更加高效？ 总体来说，Quick Union 是比 Quick Find 更加高效的。 //todo::
伪代码 public class UnionFind { int root[]; public UnionFind(int size) { root = new int[size]; for (int i = 0; i &amp;lt; size; i++) { root[i] = i; } } public int find(int x) { while (x != root[x]) { x = root[x]; } return x; } public void union(int x, int y) { int rootX = find(x); int rootY = find(y); if (rootX !</description>
    </item>
    
    <item>
      <title>2.消息系统原理</title>
      <link>https://ruichengm1987.github.io/docs/kafka/2.%E6%B6%88%E6%81%AF%E7%B3%BB%E7%BB%9F%E5%8E%9F%E7%90%86/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ruichengm1987.github.io/docs/kafka/2.%E6%B6%88%E6%81%AF%E7%B3%BB%E7%BB%9F%E5%8E%9F%E7%90%86/</guid>
      <description>2.消息系统原理 一个消息系统负责将数据从一个应用传递到另外一个应用，应用只需关注于数据，无需关注数据在两个 或多个应用间是如何传递的。
点对点消息传递  在点对点消息系统中，消息持久化到一个队列中。此时，将有一个或多个消费者消费队列中的数 据。但是一条消息只能被消费一次。 当一个消费者消费了队列中的某条数据之后，该条数据则从消息队列中删除。 该模式即使有多个消费者同时消费数据，也能保证数据处理的顺序。 基于推送模型的消息系统，由消息代理记录消费状态。  消息代理将消息推送(push)到消费者后，标记这条消息为已经被消费，但是这种方式无法很 好地保证消费的处理语义。      发布订阅消息传递  在发布-订阅消息系统中，消息被持久化到一个topic中。 消费者可以订阅一个或多个topic，消费者可以消费该topic中所有的数据，同一条数据可以被多个 消费者消费，数据被消费后不会立马删除。 在发布-订阅消息系统中，消息的生产者称为发布者，消费者称为订阅者。 Kafka 采取拉取模型(Poll)，由自己控制消费速度，以及消费的进度，消费者可以按照任意的偏移 量进行消费。    </description>
    </item>
    
    <item>
      <title>3.2.深度优先搜索算法-遍历两点之间所有路径</title>
      <link>https://ruichengm1987.github.io/docs/algorithm/%E5%9B%BE/3.%E5%9B%BE%E7%9A%84%E6%B7%B1%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2%E7%AE%97%E6%B3%95-/3.2.%E6%B7%B1%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2%E7%AE%97%E6%B3%95-%E9%81%8D%E5%8E%86%E4%B8%A4%E7%82%B9%E4%B9%8B%E9%97%B4%E6%89%80%E6%9C%89%E8%B7%AF%E5%BE%84/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ruichengm1987.github.io/docs/algorithm/%E5%9B%BE/3.%E5%9B%BE%E7%9A%84%E6%B7%B1%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2%E7%AE%97%E6%B3%95-/3.2.%E6%B7%B1%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2%E7%AE%97%E6%B3%95-%E9%81%8D%E5%8E%86%E4%B8%A4%E7%82%B9%E4%B9%8B%E9%97%B4%E6%89%80%E6%9C%89%E8%B7%AF%E5%BE%84/</guid>
      <description>3.2.深度优先搜索算法-遍历两点之间所有路径 代码   </description>
    </item>
    
    <item>
      <title>拷贝</title>
      <link>https://ruichengm1987.github.io/docs/vbox/%E6%8B%B7%E8%B4%9D/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ruichengm1987.github.io/docs/vbox/%E6%8B%B7%E8%B4%9D/</guid>
      <description>拷贝    修改配置 /etc/sysconfig/network-scripts/ifcfg-enp0s3 /etc/sysconfig/network-scripts/ifcfg-enp0s8 注意: 参考配置网卡里面的配置</description>
    </item>
    
    <item>
      <title>选择排序</title>
      <link>https://ruichengm1987.github.io/docs/algorithm/%E6%8E%92%E5%BA%8F/on2/%E9%80%89%E6%8B%A9%E6%8E%92%E5%BA%8F/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ruichengm1987.github.io/docs/algorithm/%E6%8E%92%E5%BA%8F/on2/%E9%80%89%E6%8B%A9%E6%8E%92%E5%BA%8F/</guid>
      <description>选择排序 选择排序的思想是：双重循环遍历数组，每经过一轮比较，找到最小元素的下标，将其交换至首位。
package main import &amp;quot;fmt&amp;quot; func main() { values1 := []int{4, 93, 84, 85, 80, 37, 81, 93, 27, 12} fmt.Println(values1) // [4 93 84 85 80 37 81 93 27 12] SelectSort(values1) fmt.Println(values1) // [4 12 27 37 80 81 84 85 93 93] values2 := []int{4, 93, 84, 85, 80, 37, 81, 93, 27, 12} fmt.Println(values2) // [4 93 84 85 80 37 81 93 27 12] SelectSort(values2) fmt.</description>
    </item>
    
    <item>
      <title>2.3.按秩合并的「并查集」</title>
      <link>https://ruichengm1987.github.io/docs/algorithm/%E5%9B%BE/2.%E5%B9%B6%E6%9F%A5%E9%9B%86/2.3.%E6%8C%89%E7%A7%A9%E5%90%88%E5%B9%B6%E7%9A%84%E5%B9%B6%E6%9F%A5%E9%9B%86/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ruichengm1987.github.io/docs/algorithm/%E5%9B%BE/2.%E5%B9%B6%E6%9F%A5%E9%9B%86/2.3.%E6%8C%89%E7%A7%A9%E5%90%88%E5%B9%B6%E7%9A%84%E5%B9%B6%E6%9F%A5%E9%9B%86/</guid>
      <description>2.3.按秩合并的「并查集」 小伙伴看到这里的时候，我们其实已经实现了 2 种「并查集」。但它们都有一个很大的缺点，这个缺点就是通过 union 函数连接顶点之后，可能所有顶点连成一条线形成「图 5. 一条线的图」，这就是我们 find 函数在最坏的情况下的样子。那么我们有办法解决吗？
当然，伟大的科学家已经给出了解决方案，就是按秩合并。这里的「秩」可以理解为「秩序」。之前我们在 union 的时候，我们是随机选择 x 和 y 中的一个根节点/父节点作为另一个顶点的根节点。但是在「按秩合并」中，我们是按照「某种秩序」选择一个父节点。
这里的「秩」指的是每个顶点所处的高度。我们每次 union 两个顶点的时候，选择根节点的时候不是随机的选择某个顶点的根节点，而是将「秩」大的那个根节点作为两个顶点的根节点，换句话说，我们将低的树合并到高的树之下，将高的树的根节点作为两个顶点的根节点。这样，我们就避免了所有的顶点连成一条线，这就是按秩合并优化的「并查集」。  图5.一条线的图    伪代码 // UnionFind.class public class UnionFind { int root[]; int rank[]; public UnionFind(int size) { root = new int[size]; rank = new int[size]; for (int i = 0; i &amp;lt; size; i++) { root[i] = i; rank[i] = 1; } } public int find(int x) { while (x !</description>
    </item>
    
    <item>
      <title>3.kafka简介</title>
      <link>https://ruichengm1987.github.io/docs/kafka/3.kafka%E7%AE%80%E4%BB%8B/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ruichengm1987.github.io/docs/kafka/3.kafka%E7%AE%80%E4%BB%8B/</guid>
      <description>kafka简介   官网： http://kafka.apache.org
  Kafka是由Apache软件基金会开发的一个开源流处理平台，由Scala和Java编写。Kafka是一种高吞 吐量的分布式发布订阅消息系统，它可以处理消费者在网站中的所有动作流数据。    设计目标  以时间复杂度为O(1)的方式提供消息持久化能力，即使对TB级以上数据也能保证常数时间的访问 性能。 高吞吐率。即使在非常廉价的商用机器上也能做到单机支持每秒100K条消息的传输。 支持Kafka Server间的消息分区，及分布式消费，同时保证每个partition内的消息顺序传输。 同时支持离线数据处理和实时数据处理。 支持在线水平扩展  Kafka的优点   解耦
在项目启动之初来预测将来项目会碰到什么需求，是极其困难的。消息系统在处理过程中间插入了一个 隐含的、基于数据的接口层，两边的处理过程都要实现这一接口。这允许你独立的扩展或修改两边的处 理过程，只要确保它们遵守同样的接口约束。
  冗余
有些情况下，处理数据的过程会失败。除非数据被持久化，否则将造成丢失。消息队列把数据进行持久 化直到它们已经被完全处理，通过这一方式规避了数据丢失风险。许多消息队列所采用的&amp;quot;插入-获取-删 除&amp;quot;范式中，在把一个消息从队列中删除之前，需要你的处理系统明确的指出该消息已经被处理完毕， 从而确保你的数据被安全的保存直到你使用完毕。
  扩展性
因为消息队列解耦了你的处理过程，所以增大消息入队和处理的频率是很容易的，只要另外增加处理过 程即可。不需要改变代码、不需要调节参数。扩展就像调大电力按钮一样简单。
  灵活性&amp;amp;峰值处理能力
在访问量剧增的情况下，应用仍然需要继续发挥作用，但是这样的突发流量并不常见；如果为以能处理 这类峰值访问为标准来投入资源随时待命无疑是巨大的浪费。使用消息队列能够使关键组件顶住突发的 访问压力，而不会因为突发的超负荷的请求而完全崩溃。
  可恢复性
系统的一部分组件失效时，不会影响到整个系统。消息队列降低了进程间的耦合度，所以即使一个处理 消息的进程挂掉，加入队列中的消息仍然可以在系统恢复后被处理。
  顺序保证
在大多使用场景下，数据处理的顺序都很重要。大部分消息队列本来就是排序的，并且能保证数据会按 照特定的顺序来处理。Kafka保证一个Partition内的消息的有序性。
  缓冲
在任何重要的系统中，都会有需要不同的处理时间的元素。例如，加载一张图片比应用过滤器花费更少 的时间。消息队列通过一个缓冲层来帮助任务最高效率的执行———写入队列的处理会尽可能的快速。 该缓冲有助于控制和优化数据流经过系统的速度。
  异步通信 很多时候，用户不想也不需要立即处理消息。消息队列提供了异步处理机制，允许用户把一个消息放入 队列，但并不立即处理它。想向队列中放入多少消息就放多少，然后在需要的时候再去处理它们。
  </description>
    </item>
    
    <item>
      <title>插入排序</title>
      <link>https://ruichengm1987.github.io/docs/algorithm/%E6%8E%92%E5%BA%8F/on2/%E6%8F%92%E5%85%A5%E6%8E%92%E5%BA%8F/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ruichengm1987.github.io/docs/algorithm/%E6%8E%92%E5%BA%8F/on2/%E6%8F%92%E5%85%A5%E6%8E%92%E5%BA%8F/</guid>
      <description>插入排序 插入排序有两种写法：  交换法：在新数字插入过程中，不断与前面的数字交换，直到找到自己合适的位置。 移动法：在新数字插入过程中，与前面的数字不断比较，前面的数字不断向后挪出位置，当新数字找到自己的位置后，插入一次即可。  </description>
    </item>
    
    <item>
      <title>2.4.路径压缩优化的「并查集」</title>
      <link>https://ruichengm1987.github.io/docs/algorithm/%E5%9B%BE/2.%E5%B9%B6%E6%9F%A5%E9%9B%86/2.4.%E8%B7%AF%E5%BE%84%E5%8E%8B%E7%BC%A9%E4%BC%98%E5%8C%96%E7%9A%84%E5%B9%B6%E6%9F%A5%E9%9B%86/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ruichengm1987.github.io/docs/algorithm/%E5%9B%BE/2.%E5%B9%B6%E6%9F%A5%E9%9B%86/2.4.%E8%B7%AF%E5%BE%84%E5%8E%8B%E7%BC%A9%E4%BC%98%E5%8C%96%E7%9A%84%E5%B9%B6%E6%9F%A5%E9%9B%86/</guid>
      <description>2.4.路径压缩优化的「并查集」 从前面的「并查集」实现方式中，我们不难看出，要想找到一个元素的根节点，需要沿着它的父亲节点的足迹一直遍历下去，直到找到它的根节点为止。如果下次再查找同一个元素的根节点，我们还是要做相同的操作。那我们有没有什么办法将它升级优化下呢？
答案是可以的！如果我们在找到根节点之后，将所有遍历过的元素的父节点都改成根节点，那么我们下次再查询到相同元素的时候，我们就仅仅只需要遍历两个元素就可以找到它的根节点了，这是非常高效的实现方式。那么问题来了，我们如何将所有遍历过的元素的父节点都改成根节点呢？这里就要拿出「递归」算法了。这种优化我们称之为「路径压缩」优化，它是对 find 函数的一种优化。
伪代码 // UnionFind.class public class UnionFind { int root[]; public UnionFind(int size) { root = new int[size]; for (int i = 0; i &amp;lt; size; i++) { root[i] = i; } } public int find(int x) { if (x == root[x]) { return x; } return root[x] = find(root[x]); } public void union(int x, int y) { int rootX = find(x); int rootY = find(y); if (rootX !</description>
    </item>
    
    <item>
      <title>4.kafka系统架构</title>
      <link>https://ruichengm1987.github.io/docs/kafka/4.kafka%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ruichengm1987.github.io/docs/kafka/4.kafka%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84/</guid>
      <description>4.kafka系统架构  Broker  Kafka 集群包含一个或多个服务器，服务器节点称为broker。  Topic (类似表)  每条发布到Kafka集群的消息都有一个类别，这个类别被称为Topic。 类似于数据库的表名或者ES的Index 物理上不同Topic的消息分开存储 逻辑上一个Topic的消息虽然保存于一个或多个broker上但用户只需指定消息的Topic即可生产或消 费数据而不必关心数据存于何处） 创建流程  1.controller在ZooKeeper的/brokers/topics节点上注册watcher，当topic被创建， 则 controller会通过watch得到该topic的partition/replica分配。 2.controller从/brokers/ids读取当前所有可用的broker列表，对于set_p中的每一个 partition： 2.1从分配给该partition的所有replica（称为AR）中任选一个可用的broker作为新的 leader， 并将AR设置为新的ISR 2.2将新的leader和ISR写 入/brokers/topics/[topic]/partitions/[partition]/state 3.controller通过RPC向相关的broker发送LeaderAndISRRequest。  删除流程  1.controller在zooKeeper的/brokers/topics节点上注册watcher，当topic被删除， 则controller会通过watch得到该topic的partition/replica分配。 2.若delete.topic.enable=false，结束；否则controller注册在/admin/delete_topics上 的watch被fire, controller通过回调向对应的broker发送StopReplicaRequest。 Partition (分区表的)   topic中的数据分割为一个或多个partition。 每个topic至少有一个partition,当生产者产生数据的时候，根据分配策略,选择分区,然后将消息追 加到指定的分区的末尾（队列）  ## Partation数据路由规则 1. 指定了 patition，则直接使用； 2. 未指定 patition 但指定 key，通过对 key 的 value 进行hash 选出一个 patition 3. patition 和 key 都未指定，使用轮询选出一个 patition。  每条消息都会有一个自增的编号  标识顺序 用于标识消息的偏移量   每个partition中的数据使用多个segment文件存储。 partition中的数据是有序的，不同partition间的数据丢失了数据的顺序。 如果topic有多个partition，消费数据时就不能保证数据的顺序。严格保证消息的消费顺序的场景 下，需要将partition数目设为1。  Leader (读写) 每个partition有多个副本，其中有且仅有一个作为Leader，Leader是当前负责数据的读写的 partition。</description>
    </item>
    
    <item>
      <title>2.5.基于路径压缩的按秩合并优化的「并查集」</title>
      <link>https://ruichengm1987.github.io/docs/algorithm/%E5%9B%BE/2.%E5%B9%B6%E6%9F%A5%E9%9B%86/2.5.%E5%9F%BA%E4%BA%8E%E8%B7%AF%E5%BE%84%E5%8E%8B%E7%BC%A9%E7%9A%84%E6%8C%89%E7%A7%A9%E5%90%88%E5%B9%B6%E4%BC%98%E5%8C%96%E7%9A%84%E5%B9%B6%E6%9F%A5%E9%9B%86/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ruichengm1987.github.io/docs/algorithm/%E5%9B%BE/2.%E5%B9%B6%E6%9F%A5%E9%9B%86/2.5.%E5%9F%BA%E4%BA%8E%E8%B7%AF%E5%BE%84%E5%8E%8B%E7%BC%A9%E7%9A%84%E6%8C%89%E7%A7%A9%E5%90%88%E5%B9%B6%E4%BC%98%E5%8C%96%E7%9A%84%E5%B9%B6%E6%9F%A5%E9%9B%86/</guid>
      <description>2.5.基于路径压缩的按秩合并优化的「并查集」 这个优化就是将「路径压缩优化」和「按秩合并优化」合并后形成的「并查集」的实现方式。
伪代码 // UnionFind.class public class UnionFind { int root[]; // 添加了 rank 数组来记录每个顶点的高度，也就是每个顶点的「秩」 int rank[]; public UnionFind(int size) { root = new int[size]; rank = new int[size]; for (int i = 0; i &amp;lt; size; i++) { root[i] = i; rank[i] = 1; // 一开始每个顶点的初始「秩」为1，因为它们只有自己本身的一个顶点。 } } // 此处的 find 函数与路径压优化缩版本的 find 函数一样。 public int find(int x) { if (x == root[x]) { return x; } return root[x] = find(root[x]); } // 按秩合并优化的 union 函数 public void union(int x, int y) { int rootX = find(x); int rootY = find(y); if (rootX !</description>
    </item>
    
    <item>
      <title>5.kafka环境搭建</title>
      <link>https://ruichengm1987.github.io/docs/kafka/5.kafka%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ruichengm1987.github.io/docs/kafka/5.kafka%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/</guid>
      <description>5.kafka环境搭建 </description>
    </item>
    
    <item>
      <title>2.6.「并查集」数据结构总结</title>
      <link>https://ruichengm1987.github.io/docs/algorithm/%E5%9B%BE/2.%E5%B9%B6%E6%9F%A5%E9%9B%86/2.6.%E5%B9%B6%E6%9F%A5%E9%9B%86%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E6%80%BB%E7%BB%93/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ruichengm1987.github.io/docs/algorithm/%E5%9B%BE/2.%E5%B9%B6%E6%9F%A5%E9%9B%86/2.6.%E5%B9%B6%E6%9F%A5%E9%9B%86%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E6%80%BB%E7%BB%93/</guid>
      <description>2.6.「并查集」数据结构总结 在「并查集」数据结构中，其中心思想是将所有连接的顶点，无论是直接连接还是间接连接，都将他们指向同一个父节点或者根节点。此时，如果要判断两个顶点是否具有连通性，只要判断它们的根节点是否为同一个节点即可。
在「并查集」数据结构中，它的两个灵魂函数，分别是 find和 union。find 函数是为了找出给定顶点的根节点。 union 函数是通过更改顶点根节点的方式，将两个原本不相连接的顶点表示为两个连接的顶点。对于「并查集」来说，它还有一个重要的功能性函数 connected。它最主要的作用就是检查两个顶点的「连通性」。find 和 union 函数是「并查集」中必不可少的函数。connected 函数则需要根据题目的意思来决定是否需要。
「并查集」代码基本结构 public class UnionFind { // UnionFind 的构造函数，size 为 root 数组的长度 public UnionFind(int size) {} public int find(int x) {} public void union(int x, int y) {} public boolean connected(int x, int y) {} } 「并查集」的 find 函数 它主要是用于查找顶点 x 的根结点。
 find 函数的基本实现  public int find(int x) { while (x != root[x]) { x = root[x]; } return x; }  find 函数的优化 - 路径压缩  public int find(int x) { if (x == root[x]) { return x; } return root[x] = find(root[x]); } 「并查集」的 union 函数 它主要是连接两个顶点 x 和 y 。将它们的根结点变成相同的，即代表它们来自于同一个根节点。</description>
    </item>
    
    <item>
      <title>6.kafka数据检索机制</title>
      <link>https://ruichengm1987.github.io/docs/kafka/6.kafka%E6%95%B0%E6%8D%AE%E6%A3%80%E7%B4%A2%E6%9C%BA%E5%88%B6/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ruichengm1987.github.io/docs/kafka/6.kafka%E6%95%B0%E6%8D%AE%E6%A3%80%E7%B4%A2%E6%9C%BA%E5%88%B6/</guid>
      <description>6.kafka数据检索机制   topic在物理层面以partition为分组，一个topic可以分成若干个partition partition还可以细分为Segment，一个partition物理上由多个Segment组成  segment 的参数有两个：  log.segment.bytes：单个segment可容纳的最大数据量，默认为1GB log.segment.ms：Kafka在commit一个未写满的segment前，所等待的时间（默认为7 天）     LogSegment 文件由两部分组成，分别为“.index”文件和“.log”文件，分别表示为 Segment 索引文 件和数据文件。  partition全局的第一个segment从0开始，后续每个segment文件名为上一个segment文件 最后一条消息的offset值 数值大小为64位，20位数字字符长度，没有数字用0填充 第一个segment 00000000000000000000.index 00000000000000000000.log 第二个segment，文件命名以第一个segment的最后一条消息的offset组成 00000000000000170410.index 00000000000000170410.log 第三个segment，文件命名以上一个segment的最后一条消息的offset组成 00000000000000239430.index 00000000000000239430.log    消息都具有固定的物理结构，包括：offset(8 Bytes)、消息体的大小(4 Bytes)、crc32(4 Bytes)、 magic(1 Byte)、attributes(1 Byte)、key length(4 Bytes)、key(K Bytes)、payload(N Bytes)等等 字段，可以确定一条消息的大小，即读取到哪里截止。    </description>
    </item>
    
    <item>
      <title>7.数据的安全性</title>
      <link>https://ruichengm1987.github.io/docs/kafka/7.%E6%95%B0%E6%8D%AE%E7%9A%84%E5%AE%89%E5%85%A8%E6%80%A7/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ruichengm1987.github.io/docs/kafka/7.%E6%95%B0%E6%8D%AE%E7%9A%84%E5%AE%89%E5%85%A8%E6%80%A7/</guid>
      <description>7.数据的安全性 producer delivery guarantee 0. At least one 消息绝不会丢，但可能会重复传输 1. At most once 消息可能会丢，但绝不会重复传输 2. Exactly once 每条消息肯定会被传输一次且仅传输一次  Producers可以选择是否为数据的写入接收ack，有以下几种ack的选项：request.required.acks  acks=0 * Producer 在 ISR 中的 Leader 已成功收到的数据并得到确认后发送下一条 Message。 acks=1 * 这意味着 Producer 无需等待来自 Broker 的确认而继续发送下一批消息。 acks=all * Producer 需要等待 ISR 中的所有 Follower 都确认接收到数据后才算一次发送完成，可 靠性最高。    ISR机制  关键词  AR : Assigned Replicas 用来标识副本的全集 OSR ： out -sync Replicas 离开同步队列的副本 ISR ： in -sync Replicas 加入同步队列的副本 ISR = Leader + 没有落后太多的副本;AR = OSR+ ISR。   我们备份数据就是防止数据丢失，当主节点挂掉时，可以启用备份节点  producer&amp;ndash;push&amp;ndash;&amp;gt;leader leader&amp;ndash;pull&amp;ndash;&amp;gt;follower Follower每间隔一定时间去Leader拉取数据，来保证数据的同步   ISR(in-syncReplica  当主节点挂点，并不是去Follower选择主，而是从ISR中选择主 判断标准  超过10秒钟没有同步数据  replica.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://ruichengm1987.github.io/docs/algorithm/%E5%9B%BE/5.%E6%9C%80%E5%B0%8F%E7%94%9F%E6%88%90%E6%A0%91%E7%9B%B8%E5%85%B3%E7%AE%97%E6%B3%95/5.1.%E5%88%87%E5%88%86%E5%AE%9A%E7%90%86/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ruichengm1987.github.io/docs/algorithm/%E5%9B%BE/5.%E6%9C%80%E5%B0%8F%E7%94%9F%E6%88%90%E6%A0%91%E7%9B%B8%E5%85%B3%E7%AE%97%E6%B3%95/5.1.%E5%88%87%E5%88%86%E5%AE%9A%E7%90%86/</guid>
      <description></description>
    </item>
    
    <item>
      <title></title>
      <link>https://ruichengm1987.github.io/docs/algorithm/%E5%9B%BE/5.%E6%9C%80%E5%B0%8F%E7%94%9F%E6%88%90%E6%A0%91%E7%9B%B8%E5%85%B3%E7%AE%97%E6%B3%95/5.2.kruskal%E7%AE%97%E6%B3%95/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ruichengm1987.github.io/docs/algorithm/%E5%9B%BE/5.%E6%9C%80%E5%B0%8F%E7%94%9F%E6%88%90%E6%A0%91%E7%9B%B8%E5%85%B3%E7%AE%97%E6%B3%95/5.2.kruskal%E7%AE%97%E6%B3%95/</guid>
      <description></description>
    </item>
    
    <item>
      <title></title>
      <link>https://ruichengm1987.github.io/docs/algorithm/%E5%9B%BE/5.%E6%9C%80%E5%B0%8F%E7%94%9F%E6%88%90%E6%A0%91%E7%9B%B8%E5%85%B3%E7%AE%97%E6%B3%95/5.3.prim%E7%AE%97%E6%B3%95/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ruichengm1987.github.io/docs/algorithm/%E5%9B%BE/5.%E6%9C%80%E5%B0%8F%E7%94%9F%E6%88%90%E6%A0%91%E7%9B%B8%E5%85%B3%E7%AE%97%E6%B3%95/5.3.prim%E7%AE%97%E6%B3%95/</guid>
      <description></description>
    </item>
    
    <item>
      <title></title>
      <link>https://ruichengm1987.github.io/docs/redis/%E7%BC%93%E5%AD%98/%E7%BC%93%E5%AD%98%E7%A9%BF%E9%80%8F/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ruichengm1987.github.io/docs/redis/%E7%BC%93%E5%AD%98/%E7%BC%93%E5%AD%98%E7%A9%BF%E9%80%8F/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>