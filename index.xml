<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Introduction on 笔记本</title>
    <link>https://ruichengm1987.github.io/</link>
    <description>Recent content in Introduction on 笔记本</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    
	<atom:link href="https://ruichengm1987.github.io/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>1.异步通信原理</title>
      <link>https://ruichengm1987.github.io/docs/kafka/1.%E5%BC%82%E6%AD%A5%E9%80%9A%E4%BF%A1%E5%8E%9F%E7%90%86/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ruichengm1987.github.io/docs/kafka/1.%E5%BC%82%E6%AD%A5%E9%80%9A%E4%BF%A1%E5%8E%9F%E7%90%86/</guid>
      <description>1.异步通信原理 观察者模式  观察者模式（Observer），又叫发布-订阅模式（Publish/Subscribe） 定义对象间一种一对多的依赖关系，使得每当一个对象改变状态，则所有依赖于它的对象都会得到 通知并自动更新。 一个对象（目标对象）的状态发生改变，所有的依赖对象（观察者对象）都将得到通知。   现实生活中的应用场景  京东到货通知    生产者消费者模式  传统模式  生产者直接将消息传递给指定的消费者 耦合性特别高，当生产者或者消费者发生变化，都需要重写业务逻辑   生产者消费者模式  通过一个容器来解决生产者和消费者的强耦合问题。生产者和消费者彼此之间不直接通讯，而通过阻塞队列来进行通讯     数据传递流程  生产者消费者模式，即N个线程进行生产，同时N个线程进行消费，两种角色通过内存缓冲区 进行通信， 生产者负责向缓冲区里面添加数据单元 消费者负责从缓冲区里面取出数据单元  一般遵循先进先出的原则      缓冲区  解耦  假设生产者和消费者分别是两个类。如果让生产者直接调用消费者的某个方法，那么生产者 对于消费者就会产生依赖   支持并发  生产者直接调用消费者的某个方法过程中函数调用是同步的 万一消费者处理数据很慢，生产者就会白白糟蹋大好时光    数据单元  关联到业务对象  数据单元必须关联到某种业务对象   完整性  就是在传输过程中，要保证该数据单元的完整   独立性  就是各个数据单元之间没有互相依赖 某个数据单元传输失败不应该影响已经完成传输的单元；也不应该影响尚未传输的单元。   颗粒度  数据单元需要关联到某种业务对象。那么数据单元和业务对象应该处于的关系（一对一？一 对多） 如果颗粒度过小会增加数据传输的次数 如果颗粒度过大会增加单个数据传输的时间，影响后期消费    </description>
    </item>
    
    <item>
      <title>配置网卡</title>
      <link>https://ruichengm1987.github.io/docs/vbox/%E9%85%8D%E7%BD%AE%E7%BD%91%E5%8D%A1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ruichengm1987.github.io/docs/vbox/%E9%85%8D%E7%BD%AE%E7%BD%91%E5%8D%A1/</guid>
      <description>配置网卡 https://blog.csdn.net/weixin_42541479/article/details/118407951
1、安装centos7的时候注意选择两个网卡 两个网卡分别为：
nat(虚拟机访问互联网，使用10.0.2.x段)
host-only(虚拟机和主机互相通信，使用192.168.56.x段)
在偏好设置里面设置网络。如下图配置：
    2、配置网络    3、开机，进入 cd /etc/etc/sysconfig/network-scripts/ 目录 cd /etc/sysconfig/network-scripts/ ls   vi ifcfg-enp0s3   vi ifcfg-enp0s8   service network restart   4、验证    拷贝 </description>
    </item>
    
    <item>
      <title>2.消息系统原理</title>
      <link>https://ruichengm1987.github.io/docs/kafka/2.%E6%B6%88%E6%81%AF%E7%B3%BB%E7%BB%9F%E5%8E%9F%E7%90%86/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ruichengm1987.github.io/docs/kafka/2.%E6%B6%88%E6%81%AF%E7%B3%BB%E7%BB%9F%E5%8E%9F%E7%90%86/</guid>
      <description>2.消息系统原理 一个消息系统负责将数据从一个应用传递到另外一个应用，应用只需关注于数据，无需关注数据在两个 或多个应用间是如何传递的。
点对点消息传递  在点对点消息系统中，消息持久化到一个队列中。此时，将有一个或多个消费者消费队列中的数 据。但是一条消息只能被消费一次。 当一个消费者消费了队列中的某条数据之后，该条数据则从消息队列中删除。 该模式即使有多个消费者同时消费数据，也能保证数据处理的顺序。 基于推送模型的消息系统，由消息代理记录消费状态。  消息代理将消息推送(push)到消费者后，标记这条消息为已经被消费，但是这种方式无法很 好地保证消费的处理语义。      发布订阅消息传递  在发布-订阅消息系统中，消息被持久化到一个topic中。 消费者可以订阅一个或多个topic，消费者可以消费该topic中所有的数据，同一条数据可以被多个 消费者消费，数据被消费后不会立马删除。 在发布-订阅消息系统中，消息的生产者称为发布者，消费者称为订阅者。 Kafka 采取拉取模型(Poll)，由自己控制消费速度，以及消费的进度，消费者可以按照任意的偏移 量进行消费。    </description>
    </item>
    
    <item>
      <title>拷贝</title>
      <link>https://ruichengm1987.github.io/docs/vbox/%E6%8B%B7%E8%B4%9D/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ruichengm1987.github.io/docs/vbox/%E6%8B%B7%E8%B4%9D/</guid>
      <description>拷贝    修改配置 /etc/sysconfig/network-scripts/ifcfg-enp0s3 /etc/sysconfig/network-scripts/ifcfg-enp0s8 注意: 参考配置网卡里面的配置</description>
    </item>
    
    <item>
      <title>3.kafka简介</title>
      <link>https://ruichengm1987.github.io/docs/kafka/3.kafka%E7%AE%80%E4%BB%8B/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ruichengm1987.github.io/docs/kafka/3.kafka%E7%AE%80%E4%BB%8B/</guid>
      <description>kafka简介   官网： http://kafka.apache.org
  Kafka是由Apache软件基金会开发的一个开源流处理平台，由Scala和Java编写。Kafka是一种高吞 吐量的分布式发布订阅消息系统，它可以处理消费者在网站中的所有动作流数据。    设计目标  以时间复杂度为O(1)的方式提供消息持久化能力，即使对TB级以上数据也能保证常数时间的访问 性能。 高吞吐率。即使在非常廉价的商用机器上也能做到单机支持每秒100K条消息的传输。 支持Kafka Server间的消息分区，及分布式消费，同时保证每个partition内的消息顺序传输。 同时支持离线数据处理和实时数据处理。 支持在线水平扩展  Kafka的优点   解耦
在项目启动之初来预测将来项目会碰到什么需求，是极其困难的。消息系统在处理过程中间插入了一个 隐含的、基于数据的接口层，两边的处理过程都要实现这一接口。这允许你独立的扩展或修改两边的处 理过程，只要确保它们遵守同样的接口约束。
  冗余
有些情况下，处理数据的过程会失败。除非数据被持久化，否则将造成丢失。消息队列把数据进行持久 化直到它们已经被完全处理，通过这一方式规避了数据丢失风险。许多消息队列所采用的&amp;quot;插入-获取-删 除&amp;quot;范式中，在把一个消息从队列中删除之前，需要你的处理系统明确的指出该消息已经被处理完毕， 从而确保你的数据被安全的保存直到你使用完毕。
  扩展性
因为消息队列解耦了你的处理过程，所以增大消息入队和处理的频率是很容易的，只要另外增加处理过 程即可。不需要改变代码、不需要调节参数。扩展就像调大电力按钮一样简单。
  灵活性&amp;amp;峰值处理能力
在访问量剧增的情况下，应用仍然需要继续发挥作用，但是这样的突发流量并不常见；如果为以能处理 这类峰值访问为标准来投入资源随时待命无疑是巨大的浪费。使用消息队列能够使关键组件顶住突发的 访问压力，而不会因为突发的超负荷的请求而完全崩溃。
  可恢复性
系统的一部分组件失效时，不会影响到整个系统。消息队列降低了进程间的耦合度，所以即使一个处理 消息的进程挂掉，加入队列中的消息仍然可以在系统恢复后被处理。
  顺序保证
在大多使用场景下，数据处理的顺序都很重要。大部分消息队列本来就是排序的，并且能保证数据会按 照特定的顺序来处理。Kafka保证一个Partition内的消息的有序性。
  缓冲
在任何重要的系统中，都会有需要不同的处理时间的元素。例如，加载一张图片比应用过滤器花费更少 的时间。消息队列通过一个缓冲层来帮助任务最高效率的执行———写入队列的处理会尽可能的快速。 该缓冲有助于控制和优化数据流经过系统的速度。
  异步通信 很多时候，用户不想也不需要立即处理消息。消息队列提供了异步处理机制，允许用户把一个消息放入 队列，但并不立即处理它。想向队列中放入多少消息就放多少，然后在需要的时候再去处理它们。
  </description>
    </item>
    
    <item>
      <title>4.kafka系统架构</title>
      <link>https://ruichengm1987.github.io/docs/kafka/4.kafka%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ruichengm1987.github.io/docs/kafka/4.kafka%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84/</guid>
      <description>4.kafka系统架构  Broker  Kafka 集群包含一个或多个服务器，服务器节点称为broker。  Topic (类似表)  每条发布到Kafka集群的消息都有一个类别，这个类别被称为Topic。 类似于数据库的表名或者ES的Index 物理上不同Topic的消息分开存储 逻辑上一个Topic的消息虽然保存于一个或多个broker上但用户只需指定消息的Topic即可生产或消 费数据而不必关心数据存于何处） 创建流程  1.controller在ZooKeeper的/brokers/topics节点上注册watcher，当topic被创建， 则 controller会通过watch得到该topic的partition/replica分配。 2.controller从/brokers/ids读取当前所有可用的broker列表，对于set_p中的每一个 partition： 2.1从分配给该partition的所有replica（称为AR）中任选一个可用的broker作为新的 leader， 并将AR设置为新的ISR 2.2将新的leader和ISR写 入/brokers/topics/[topic]/partitions/[partition]/state 3.controller通过RPC向相关的broker发送LeaderAndISRRequest。  删除流程  1.controller在zooKeeper的/brokers/topics节点上注册watcher，当topic被删除， 则controller会通过watch得到该topic的partition/replica分配。 2.若delete.topic.enable=false，结束；否则controller注册在/admin/delete_topics上 的watch被fire, controller通过回调向对应的broker发送StopReplicaRequest。 Partition (分区表的)   topic中的数据分割为一个或多个partition。 每个topic至少有一个partition,当生产者产生数据的时候，根据分配策略,选择分区,然后将消息追 加到指定的分区的末尾（队列）  ## Partation数据路由规则 1. 指定了 patition，则直接使用； 2. 未指定 patition 但指定 key，通过对 key 的 value 进行hash 选出一个 patition 3. patition 和 key 都未指定，使用轮询选出一个 patition。  每条消息都会有一个自增的编号  标识顺序 用于标识消息的偏移量   每个partition中的数据使用多个segment文件存储。 partition中的数据是有序的，不同partition间的数据丢失了数据的顺序。 如果topic有多个partition，消费数据时就不能保证数据的顺序。严格保证消息的消费顺序的场景 下，需要将partition数目设为1。  Leader (读写) 每个partition有多个副本，其中有且仅有一个作为Leader，Leader是当前负责数据的读写的 partition。</description>
    </item>
    
    <item>
      <title>5.kafka环境搭建</title>
      <link>https://ruichengm1987.github.io/docs/kafka/5.kafka%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ruichengm1987.github.io/docs/kafka/5.kafka%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/</guid>
      <description>5.kafka环境搭建 </description>
    </item>
    
    <item>
      <title>6.kafka数据检索机制</title>
      <link>https://ruichengm1987.github.io/docs/kafka/6.kafka%E6%95%B0%E6%8D%AE%E6%A3%80%E7%B4%A2%E6%9C%BA%E5%88%B6/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ruichengm1987.github.io/docs/kafka/6.kafka%E6%95%B0%E6%8D%AE%E6%A3%80%E7%B4%A2%E6%9C%BA%E5%88%B6/</guid>
      <description>6.kafka数据检索机制   topic在物理层面以partition为分组，一个topic可以分成若干个partition partition还可以细分为Segment，一个partition物理上由多个Segment组成  segment 的参数有两个：  log.segment.bytes：单个segment可容纳的最大数据量，默认为1GB log.segment.ms：Kafka在commit一个未写满的segment前，所等待的时间（默认为7 天）     LogSegment 文件由两部分组成，分别为“.index”文件和“.log”文件，分别表示为 Segment 索引文 件和数据文件。  partition全局的第一个segment从0开始，后续每个segment文件名为上一个segment文件 最后一条消息的offset值 数值大小为64位，20位数字字符长度，没有数字用0填充 第一个segment 00000000000000000000.index 00000000000000000000.log 第二个segment，文件命名以第一个segment的最后一条消息的offset组成 00000000000000170410.index 00000000000000170410.log 第三个segment，文件命名以上一个segment的最后一条消息的offset组成 00000000000000239430.index 00000000000000239430.log    消息都具有固定的物理结构，包括：offset(8 Bytes)、消息体的大小(4 Bytes)、crc32(4 Bytes)、 magic(1 Byte)、attributes(1 Byte)、key length(4 Bytes)、key(K Bytes)、payload(N Bytes)等等 字段，可以确定一条消息的大小，即读取到哪里截止。    </description>
    </item>
    
    <item>
      <title>7.数据的安全性</title>
      <link>https://ruichengm1987.github.io/docs/kafka/7.%E6%95%B0%E6%8D%AE%E7%9A%84%E5%AE%89%E5%85%A8%E6%80%A7/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ruichengm1987.github.io/docs/kafka/7.%E6%95%B0%E6%8D%AE%E7%9A%84%E5%AE%89%E5%85%A8%E6%80%A7/</guid>
      <description>7.数据的安全性 producer delivery guarantee 0. At least one 消息绝不会丢，但可能会重复传输 1. At most once 消息可能会丢，但绝不会重复传输 2. Exactly once 每条消息肯定会被传输一次且仅传输一次  Producers可以选择是否为数据的写入接收ack，有以下几种ack的选项：request.required.acks  acks=0 * Producer 在 ISR 中的 Leader 已成功收到的数据并得到确认后发送下一条 Message。 acks=1 * 这意味着 Producer 无需等待来自 Broker 的确认而继续发送下一批消息。 acks=all * Producer 需要等待 ISR 中的所有 Follower 都确认接收到数据后才算一次发送完成，可 靠性最高。    ISR机制  关键词  AR : Assigned Replicas 用来标识副本的全集 OSR ： out -sync Replicas 离开同步队列的副本 ISR ： in -sync Replicas 加入同步队列的副本 ISR = Leader + 没有落后太多的副本;AR = OSR+ ISR。   我们备份数据就是防止数据丢失，当主节点挂掉时，可以启用备份节点  producer&amp;ndash;push&amp;ndash;&amp;gt;leader leader&amp;ndash;pull&amp;ndash;&amp;gt;follower Follower每间隔一定时间去Leader拉取数据，来保证数据的同步   ISR(in-syncReplica  当主节点挂点，并不是去Follower选择主，而是从ISR中选择主 判断标准  超过10秒钟没有同步数据  replica.</description>
    </item>
    
  </channel>
</rss>