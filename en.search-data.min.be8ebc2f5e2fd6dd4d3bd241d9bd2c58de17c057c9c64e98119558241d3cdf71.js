'use strict';(function(){const indexCfg={cache:true};indexCfg.doc={id:'id',field:['title','content'],store:['title','href'],};const index=FlexSearch.create('balance',indexCfg);window.bookSearchIndex=index;index.add({'id':0,'href':'/docs/algorithm/%E5%9B%BE/1.%E5%9B%BE%E7%9A%84%E5%9F%BA%E6%9C%AC%E7%9F%A5%E8%AF%86/','title':"1.「图」的基本知识",'content':"1.「图」的基本知识 「图」大概是最接近生活的一种数据结构了，生活中各种关系图便是「图」最真实的写照。比如，我们每个人的朋友交际圈就是一个巨大的「图」。  图1.小A的朋友交际图    「图」的类型 「图」的类型有很多,我们将介绍三种类型的图：无向图、有向图、加权图。\n无向图 「无向图」的图中任意两个顶点之间的边都是没有方向的。 「图1. 小A的朋友交际图」是一个无向图。\n有向图 「有向图」的图中任意两个顶点之间的边都是有方向的。 「图 2. 有向图的示例图」是一个有向图。  图2.有向图的示例图    加权图 「加权图」的图中的每条边都带有一个相关的权重。这里的权重可以是任何一种度量，比如时间，距离，尺寸等。生活中最常见的「加权图」应该就是我们的地图了。在下方的「图 3. 加权图的示例图」中，每条边上都标有距离，它们可以视为每个边上的权重。  图3.加权图的示例图    「图」的定义和相关术语 「图」是由顶点和边组成的一种非线形数据结构。在「图」中有很多相关术语来描述一个图。如果在后面的学习中遇到不认识的术语，请回到这里查看相关的定义。\n 顶点：在「图 1. 小A的朋友交际图」中，小 A 、小 B 、小 C 等均称为「图」的顶点。 边：顶点之间的连接线称为边。在「图 1. 小A的朋友交际图」中，小 A 和小 B 之间的连接线就是图中的一条边。 路径：从一个顶点到另一个顶点之间经过的所有顶点的集合。在「图 1. 小A的朋友交际图」中，从小 A 到小 C 的路径为[小A, 小B, 小C] 或者[小A, 小G, 小B, 小C]或者[小A, 小E, 小F, 小D, 小B, 小C]。 **注意：**两个顶点之间的路径可以是很多条。 路径长度：一条路径上经过的边的数量。在「图 1. 小A的朋友交际图」中，从小 A 到小 C 的路径长度为2或者3或者5。 环：起点和终点为同一个顶点的路径。在「图 1. 小A的朋友交际图」中，[小A, 小B, 小D, 小F, 小E]组成了一个环。同理，[小A, 小G, 小B]也组成了一个环。 负权环：在「加权图」中，如果一个环的所有边的权重加起来为负数，我们就称之为「负权环」。在「图4. 负权环」中，它的所有边的权重和为-3。 连通性：两个不同顶点之间存在至少一条路径，则称这两个顶点是连通的。在「图 1. 小A的朋友交际图」中，小 A 和小 C 是连通的，因为它们之间至少有一条路径。 顶点的度：「度」适用于无向图，指的是和该顶点相连接的所有边数称为顶点的度。在「图 1. 小A的朋友交际图」中，顶点小A的度为3，因为与它相连接的边有3条。 顶点的入度：「入度」适用于有向图，一个顶点的入度为dd，则表示有dd条与顶点相连的边指向该顶点。在「图 2. 有向图的示例图」中，A的入度为1，由F指向A的边。 顶点的出度：「出度」适用于有向图，它与「入度」相反。一个顶点的出度为dd，则表示有dd条与顶点相连的边以该顶点为起点。在「图 2. 有向图的示例图」中，A 的出度为3，分别为，A 指向 B 的边，A 指向 C 的边，和 A 指向 G 的边。  图4.负权环      "});index.add({'id':1,'href':'/docs/kafka/1.%E5%BC%82%E6%AD%A5%E9%80%9A%E4%BF%A1%E5%8E%9F%E7%90%86/','title':"1.异步通信原理",'content':"1.异步通信原理 观察者模式  观察者模式（Observer），又叫发布-订阅模式（Publish/Subscribe） 定义对象间一种一对多的依赖关系，使得每当一个对象改变状态，则所有依赖于它的对象都会得到 通知并自动更新。 一个对象（目标对象）的状态发生改变，所有的依赖对象（观察者对象）都将得到通知。   现实生活中的应用场景  京东到货通知    生产者消费者模式  传统模式  生产者直接将消息传递给指定的消费者 耦合性特别高，当生产者或者消费者发生变化，都需要重写业务逻辑   生产者消费者模式  通过一个容器来解决生产者和消费者的强耦合问题。生产者和消费者彼此之间不直接通讯，而通过阻塞队列来进行通讯     数据传递流程  生产者消费者模式，即N个线程进行生产，同时N个线程进行消费，两种角色通过内存缓冲区 进行通信， 生产者负责向缓冲区里面添加数据单元 消费者负责从缓冲区里面取出数据单元  一般遵循先进先出的原则      缓冲区  解耦  假设生产者和消费者分别是两个类。如果让生产者直接调用消费者的某个方法，那么生产者 对于消费者就会产生依赖   支持并发  生产者直接调用消费者的某个方法过程中函数调用是同步的 万一消费者处理数据很慢，生产者就会白白糟蹋大好时光    数据单元  关联到业务对象  数据单元必须关联到某种业务对象   完整性  就是在传输过程中，要保证该数据单元的完整   独立性  就是各个数据单元之间没有互相依赖 某个数据单元传输失败不应该影响已经完成传输的单元；也不应该影响尚未传输的单元。   颗粒度  数据单元需要关联到某种业务对象。那么数据单元和业务对象应该处于的关系（一对一？一 对多） 如果颗粒度过小会增加数据传输的次数 如果颗粒度过大会增加单个数据传输的时间，影响后期消费    "});index.add({'id':2,'href':'/docs/algorithm/%E5%9B%BE/2.%E5%B9%B6%E6%9F%A5%E9%9B%86/2.1.quick-find-%E7%9A%84%E5%B9%B6%E6%9F%A5%E9%9B%86/','title':"2.1.Quick Find 的「并查集」",'content':"2.1.Quick Find 的「并查集」 Quick Find的工作原理 //todo::\n伪代码 (todo:://提供一版go的代码) // UnionFind.class public class UnionFind { int root[]; public UnionFind(int size) { root = new int[size]; for (int i = 0; i \u0026lt; size; i++) { root[i] = i; } } public int find(int x) { return root[x]; } public void union(int x, int y) { int rootX = find(x); int rootY = find(y); if (rootX != rootY) { for (int i = 0; i \u0026lt; root.length; i++) { if (root[i] == rootY) { root[i] = rootX; } } } }; public boolean connected(int x, int y) { return find(x) == find(y); } } // App.java // 测试样例 public class App { public static void main(String[] args) throws Exception { UnionFind uf = new UnionFind(10); // 1-2-5-6-7 3-8-9 4 uf.union(1, 2); uf.union(2, 5); uf.union(5, 6); uf.union(6, 7); uf.union(3, 8); uf.union(8, 9); System.out.println(uf.connected(1, 5)); // true System.out.println(uf.connected(5, 7)); // true System.out.println(uf.connected(4, 9)); // false // 1-2-5-6-7 3-8-9-4 uf.union(9, 4); System.out.println(uf.connected(4, 9)); // true } } 时间复杂度     UnionFind 构造函数 find 函数 union 函数 connected 函数     时间复杂度 O(N) O(1) O(N) O(1)    注：NN 为「图」中顶点的个数。\n"});index.add({'id':3,'href':'/docs/notices/%E6%88%90%E7%A5%9E%E4%B9%8B%E8%B7%AF/1/','title':"2021-12-22",'content':"日期:2021-12-22（第一天） 一直想改变,一直想学点东西，工作太忙，没有恒心，大多半途而废了。\n此刻: 突然感觉我不能再这样下去了，我要开始干点什么了，那就成为自己的\u0026quot;神\u0026quot;吧,起航!!!\n我要疯狂学习4个月\n"});index.add({'id':4,'href':'/docs/algorithm/%E5%9B%BE/3.%E5%9B%BE%E7%9A%84%E6%B7%B1%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2%E7%AE%97%E6%B3%95-/3.1.%E6%B7%B1%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2%E7%AE%97%E6%B3%95-%E9%81%8D%E5%8E%86%E6%89%80%E6%9C%89%E9%A1%B6%E7%82%B9/','title':"3.1.深度优先搜索算法-遍历所有顶点",'content':"3.1.深度优先搜索算法-遍历所有顶点 代码 时间复杂度 O(V+E)。\nVV 表示顶点数，EE 表示边数。\n空间复杂度 O(V)。\nVV 表示顶点数。\n"});index.add({'id':5,'href':'/docs/algorithm/%E5%9B%BE/4.%E5%9B%BE%E7%9A%84%E5%B9%BF%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2%E7%AE%97%E6%B3%95/4.1.%E5%B9%BF%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2%E7%AE%97%E6%B3%95-%E9%81%8D%E5%8E%86%E6%89%80%E6%9C%89%E9%A1%B6%E7%82%B9/','title':"4.1.广度优先搜索算法-遍历所有顶点",'content':"4.1.广度优先搜索算法-遍历所有顶点 代码 //todo::\n时间复杂度 O(V+E)O(V+E)。\nVV 表示顶点数，EE 表示边数。\n空间复杂度 O(V)O(V)。\n"});index.add({'id':6,'href':'/docs/algorithm/%E5%9B%BE/4.%E5%9B%BE%E7%9A%84%E5%B9%BF%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2%E7%AE%97%E6%B3%95/4.2.%E5%B9%BF%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2%E7%AE%97%E6%B3%95-%E6%B1%82%E4%B8%A4%E7%82%B9%E4%B9%8B%E9%97%B4%E6%9C%80%E7%9F%AD%E8%B7%AF%E5%BE%84/','title':"4.2.广度优先搜索算法-求两点之间最短路径",'content':"4.2.广度优先搜索算法-求两点之间最短路径 代码 //todo::\n时间复杂度 O(V+E)O(V+E)。\nVV 表示顶点数，EE 表示边数。\n空间复杂度 O(V)O(V)。\nVV 表示顶点数。\n"});index.add({'id':7,'href':'/docs/algorithm/','title':"algorithm",'content':"algorithm 1: leetcode题目按照什么顺序去刷 按照一个框架来刷题目，比如说这周刷字符串,下周刷数组，按照一个章节一个章节这样来做，最好是跟着书、教程来一起做题. 做完教程的配套题目后leetcode上按频率从高到低刷,最少做每组的前20个。 做完一道题如果你比较陌生的思路， 继续做这道题的\u0026quot;相似问题\u0026rdquo;。面试题做一遍热题例如:https://leetcode-cn.com/problem-list/qg88wci/, https://leetcode-cn.com/problem-list/2cktkvj/\n参加周赛、双周赛，能做出前3个就不错了\n2: 我们需要刷多少题 400左右，看刷题质量，看到题目能默写出来\n"});index.add({'id':8,'href':'/docs/go/','title':"go",'content':"GO "});index.add({'id':9,'href':'/docs/kafka/','title':"kafka",'content':"kafka "});index.add({'id':10,'href':'/docs/algorithm/%E6%8E%92%E5%BA%8F/on2/','title':"O(n^2)",'content':"O(n^2) 本章我们介绍了三种基础排序算法：冒泡排序、选择排序、插入排序。\n冒泡排序 冒泡排序有两种优化方式：\n 记录当前轮次是否发生过交换，没有发生过交换表示数组已经有序； 记录上次发生交换的位置，下一轮排序时只比较到此位置。  选择排序 选择排序可以演变为二元选择排序：\n 二元选择排序：一次遍历选出两个值——最大值和最小值； 二元选择排序剪枝优化：当某一轮遍历出现最大值和最小值相等，表示数组中剩余元素已经全部相等。  插入排序 插入排序有两种写法：\n 交换法：新数字通过不断交换找到自己合适的位置； 移动法：旧数字不断向后移动，直到新数字找到合适的位置。  不同点 选择排序是不稳定的，冒泡排序、插入排序是稳定的；\n在这三个排序算法中，选择排序交换的次数是最少的；\n在数组几乎有序的情况下，插入排序的时间复杂度接近线性级别。\n"});index.add({'id':11,'href':'/docs/go/1.%E5%9F%BA%E7%A1%80/','title':"一、基础",'content':"一.基础 1、第一个go程序 package main //包,表明代码所在的模块(包) import \u0026quot;fmt\u0026quot; // 引入代码依赖 // 功能实现 func main() { fmt.Println(\u0026quot;hello world\u0026quot;) } 1.1、应用程序入口  必须是main包: package main 必须是main方法: func main() 文件名不一定是main.go  1.2、退出返回值 与其他主要编程语言的差异\n Go中main函数不支持任何返回值 通过os.Exit来返回状态  1.3、获取命令行参数 与其他主要编程语言的差异\n main函数不支持传入参数 func main(arg []string) 在程序中直接通过os.Args获取命令行参数  1.3、编写测试程序  源码文件以 _test结尾: xxx_test.go 测试方法名以Test方法开头: func TestXXX(t *testing.T) {\u0026hellip;}  2、基本程序结构 2.1、变量赋值 与其他主要编程语言的差异\n 赋值可以进行自动类型推断 在一个赋值语句中可以对多个变量进行同时赋值  2.2、常量定义 与其他主要编程语言的差异\n快速设置连续值\nconst ( Monday = iota + 1 Tuesday Webnesday Thursday Friday Staturday Sunday ) 2.3、数据类型 bool string int int8 int16 int32 int64 uint uint8 uint16 uint32 uint64 uintptr byte // alias for uint8 rune // alias for int32 represents a unicode code point float32 float64 complex64 complex128 2.3.1、类型转换 与其他主要编程语言的差异\n Go语言不允许隐式类型转换 别名和原有类型也不能进行隐式类型转换  2.3.2、类型的预定义值  math.MaxInt64 math.MaxFloat64 math.MaxUint32  2.3.3、指针类型 与其他主要编程语言的差异\n 不支持指针运算 string是值类型,其默认的初始化值为空字符串,而不是nil  2.4、运算符 2.4.1、算术运算符 没有前置的++ \u0026ndash;\n2.4.2、比较运算符 与其他主要编程语言的差异 用==比较数组\n 相同维数且含有相同个数元素的数组才可以比较 每个元素都相同的才相等  2.4.3、逻辑运算符 和主流语言相同\n2.4.4、位运算符 与其他主要编程语言的差异 \u0026amp;^ 按位置零\n1 \u0026amp;^ 0 -- 1 1 \u0026amp;^ 1 -- 0 0 \u0026amp;^ 1 -- 0 0 \u0026amp;^ 0 -- 0 右边的二进制是0，左边的是什么，结果就是什么 右边的二进制是1，左边的无论是什么, 结果都是0 2.5、循环 与其他主要编程语言的差异\n Go语言仅支持循环关键字for for ( j := 7; j \u0026lt;= 9; j++ ) //不需要\u0026rdquo;(\u0026ldquo;和\u0026rdquo;)\u0026quot;。  while条件循环 while(n\u0026lt;5) n := 0 for n \u0026lt; 5 { n++ fmt.Println(n) } 无限循环 while(true) n := 0 for { ... } 2.6、if条件 if condition { // code to be executed if condition is true } else { // code to be executed if condition is false } if condition-1 { // code to be executed if condition-1 is true } else if condition-2 { // code to be executed if condition-2 is true } else { // code to be executed if both condition1 and condition2 are false } 与其他主要编程语言的差异\n condition 表达式结果必须为布尔值 支持变量赋值:  if var declaration; condition { // code to be executed if condition is true } 2.7、switch条件 switch os := runtime.GOOS; os { case \u0026quot;darwin\u0026quot;: fmt.Println(\u0026quot;OS x.\u0026quot;) case \u0026quot;linux\u0026quot;: fmt.Println(\u0026quot;Linux.\u0026quot;) default: fmt.Printf(\u0026quot;%s.\u0026quot;, os) } switch { case 0 \u0026lt;= Num \u0026amp;\u0026amp; Num \u0026lt;= 3: fmt.Printf(\u0026quot;0-3\u0026quot;) case 4 \u0026lt;= Num \u0026amp;\u0026amp; Num \u0026lt;= 6: fmt.Printf(\u0026quot;4-6\u0026quot;) case 7 \u0026lt;= Num \u0026amp;\u0026amp; Num \u0026lt;= 9: fmt.Printf(\u0026quot;7-9\u0026quot;) } 与其他主要编程语言的差异\n 条件表达式不限制为常量或者整数 单个case中，可以出现多个结果选项，使用逗号分隔； 与C语言等规则相反,GO语言不需要用break来明确退出一个case 可以不设定switch之后的条件表达式，在此种情况下,整个switch结构与多个if\u0026hellip;else\u0026hellip;的逻辑作用等同  3、常用集合 3.1、数组 3.1.1、数组的声明 var a [3]int // 声明并初始化为默认零值 a[0] = 1 b := [3]int{1,2,3} // 声明同时初始化 c := [...]int{1,2,3} // 声明同时初始化 d := [2][2]int{{1,2}, {3, 4}} // 多维数组初始化 3.1.2、数组截取 a[开发索引(包含), 结果索引(不包含)]\n注:开发索引 和 结果索引 都不支持负数\n3.2、切片 3.2.1、切片内部结构 ptr: 指针\nlen: 元素的个数\ncap: 内部数组的容量\n3.2.2、切片声明 var s0 []int s0 = append(s0, 1) s := []int{] s1 := []int{1, 2, 3} s2 := make([]int, 2, 4) /* []type, len, cap 其中len个元素会被初始化为默认零值,未初始化元素不可以访问 */ 3.2.2、切片共享存储结构 切片是如何实现可变长的?\n3.3、数组vs切片  容量是否可伸缩 数据不可伸缩, 切片可伸缩 是否可以进行比较 数组相同大小，相同类型能比较，切片不能比较  3.3、Map 3.3.1、Map声明 m := map[string]int{\u0026quot;one\u0026quot;:1, \u0026quot;two\u0026quot;: 2} m1 := map[string]int{} m1[\u0026quot;three\u0026quot;] = 3 m2 := make(map[string]int, 10 /*Initial Capacity*/) // 为什么不初始化len 3.3.2、Map元素的访问 与其他主要编程语言的差异 在访问的key不存在时,仍会返回零值, 不能通过返回nil来判断元素是否存在\nif v, ok := m1[3]; ok { t.Logf(\u0026quot;key 3's value is %d\u0026quot;, v) } else { t.Log(\u0026quot;key 3 is not existing.\u0026quot;) } 3.3.3、Map遍历 m := map[string]int{\u0026quot;one\u0026quot;:1, \u0026quot;two\u0026quot;:2, \u0026quot;three\u0026quot;: 3} for k, v := range m { t.Log(k, v) } 3.3.4、Map与工厂模式  map的value可以是一个方法 与go的Dock type接口方式一起, 可以方便的实现单一方法对象的工厂模式  3.3.5、线程安全map https://github.com/easierway/concurrent_map\n3.3.6、实现Set Go的内置集合中没有Set实现,可以map[type]bool\n 元素的唯一性 基本操作  添加元素 判断元素是否存在 删除元素 元素个数    // 定义初始化 mySet := map[int]bool{} // s和值1 mySet[1] = true // 判断是否3存在 n := 3 if mySet[n] { t.Logf(\u0026quot;%d is existing\u0026quot;, n) } else { t.Logf(\u0026quot;%d is not existing\u0026quot;, n) } // 添加key 3 mySet[3] = true t.Log(len(mySet)) // 删出key 1 delete(mySet, 1) // 判断key 1 是否存在 if mySet[1] { t.Logf(\u0026quot;%d is existing\u0026quot;, 1) } else { t.Logf(\u0026quot;%d is not existing\u0026quot;, 1) } 4、字符串 与其他主要编程语言的差异\n string是数据类型，不是引用或指针类型 string是只读的byte slice，len函数可以返回它所包含的byte数 string的byte数组可以存放任何数据  4.1、Unicode UTF8  Unicode是一种字符集 (code point) UTF8 是unicode的存储实现(转换为字节序列的规则)  4.2、编码与存储    字符 \u0026ldquo;中\u0026rdquo;     Unicode 0x4E2D   UTF-8 0xE4B8AD   string/[]byte [0xE4,0xB8,0xAD]    4.3、常用字符串函数  strings包 (https://golang.org) strconv 包 (https://golang.org/pkg/strconv)  5、函数 5.1、函数是一等公民 与其他主要编程语言的差异\n 可以有多个返回值 所有参数都是值传递: slice, map, channel会有传引用的错觉 函数可以作为变量的值 函数可以作为参数和返回值  5.2、可变参数及defer 5.2.1、可变参数 func sum(ops ...int) int { s := 0 for _, op := range ops { s += op } return s } 5.2.2、defer func TestDefer(t *testing.T) { defer func() { t.Log(\u0026quot;clear resources\u0026quot;) }() t.Log(\u0026quot;Started\u0026quot;) panic(\u0026quot;Fatal error\u0026quot;) // defer仍会执行 } 6、面向对象编程 6.1、结构体定义 type Employee struct { Id string Name string Age int } e := Employee {Id : \u0026quot;1\u0026quot;} e1 := new(Employee) // 注意这里返回的引用/指针,相当于e:=\u0026amp;Employee{} e1.Id = \u0026quot;2\u0026quot; // 与其他主要编程语言的差异；通过实例的指针访问成员不需要使用-\u0026gt; 6.2、行为(方法)定义 // 第一种定义方式在实例对应方法被调用时，实例的成员会进行值复制 func (e Employee) String() string { return fmt.Sprintf(\u0026quot;ID:%s-Name:%s-Age:%d\u0026quot;, e.Id, e.Name, e.Age) } // 通常情况下为了避免内存拷贝我们使用第二种定义方式 func (e *Employee) String() string { return fmt.Sprintf(\u0026quot;ID:%s-Name:%s-Age:%d\u0026quot;, e.Id, e.Name, e.Age) } 6.3、Duck Type 式接口 type Programmer interface { WriteHelloWorld() string } type GoProgrammer struct { } func (g *GoProgrammer) WriteHelloWorld() string { return \u0026quot;fmt.Println(\\\u0026quot;Hello World\\\u0026quot;)\u0026quot; } 与其他主要编程语言的差异\n 接口为非入侵性,实现不依赖于接口定义 所有接口的定义可以包含在接口使用者包内  6.4、接口变量 var prog Code = \u0026amp;GoProgrammer{} // 类型 type GoProgrammer struct { } // 数据 \u0026amp;GoProgrammer{} 6.5、自定义类型  type IntConvertionFn func(n int) int type MyPoint int  6.6、扩展与复用 与其他主要编程语言的差异 不支持重载\n6.7、多态 package duotai import ( \u0026quot;fmt\u0026quot; \u0026quot;testing\u0026quot; ) type Programmer interface { WriteHelloWorld() string } type GoProgrammer struct { } func (p *GoProgrammer) WriteHelloWorld() string { return \u0026quot;fmt.Println(\\\u0026quot;hello world!\\\u0026quot;)\u0026quot; } type JavaProgrammer struct { } func (p *JavaProgrammer) WriteHelloWorld() string { return \u0026quot;fmt.Println(\\\u0026quot;hello world!\\\u0026quot;)\u0026quot; } func writeFirstProgram(p Programmer) { fmt.Printf(\u0026quot;%T %v\\n\u0026quot;, p, p.WriteHelloWorld()) } func TestPolymorphism(t *testing.T) { goProg := new(GoProgrammer) javaProg := new(JavaProgrammer) writeFirstProgram(goProg) writeFirstProgram(javaProg) } 6.8、空接口与断言  空接口可以表示任何类型 通过断言来将空接口转换为指定类型  v, ok := p.(int) // ok == true 时为转换成功 6.9、Go接口的最佳实践  倾向于使用小的接口定义,很多接口只包含一个方法  type Reader interface{ Read(p []byte) (n int, err error) } type Writer interface { Write(p []byte) (n int, err error) }  较大的接口定义,可以由多个小接口定义组合而成  type ReadWriter interface{ Reader Writer }  只依赖于必要功能的最小接口  func Store(reader Reader) error { ... }) 7、错误处理 7.1、Go的错误机制 与其他主要编程语言的差异\n 没有异常机制 error类型实现了error接口  type error interface { Error() string }  可以通过errors.New来快速创建错误实例  errors.New(\u0026quot;n must be in ther r ange [0, 100]\u0026quot;) 最佳实践\n定义不同的错误变量,1️以便于判断错误类型\nvar LessThanTwoError error = errors.New(\u0026quot;n must be grater than 2\u0026quot;) var GreaterThanHundredError error = errors.New(\u0026quot;n must be less than 100\u0026quot;) func TestGetFibonacci(t *testing.T) { var list []int list, err := GetFibonacci(-10) if err = LessThanTwoError { t.Error(\u0026quot;Need a large Number\u0026quot;) } if err = GreaterThanHundredError { t.Error(\u0026quot;Need a large Number\u0026quot;) } } 及早失败,避免嵌套\n7.2、panic vs recover  os.Exit退出时不会调用defer指定的函数 os.Exit退出时不输出当前调用栈信息  defer func() { if err := recover(); err != nil { fmt.Println(\u0026quot;recoverd from\u0026quot;, err) } fmt.Println(\u0026quot;Finally!\u0026quot;) }() 7.2.1、最常见的\u0026quot;错误恢复\u0026rdquo; defer func() { if err := recover(); err != nil { fmt.Println(\u0026quot;recoverd from\u0026quot;, err) } fmt.Println(\u0026quot;Finally!\u0026quot;) }() 当心！recover成为恶魔\n 形成僵尸服务进程,导致health check失败。 \u0026ldquo;Let it Crash!\u0026ldquo;往往是我们恢复不确定性错误的最好方法。  8、包和依赖管理 8.1、构建可复用的模块  基本复用模块单元\n以首字母大写来表名可被包外代码访问 代码的package可以和所在的目录不一致 同一目录里的Go代码的package要保持一致 在main被执行前,所有依赖的package的init方法都会被执行 不同包的init函数按照包导入的依赖关系决定执行顺序 每个包可以有多个init函数 包的每个源文件也可以有多个init函数,这点比较 特殊  8.2、go mod 依赖管理 "});index.add({'id':12,'href':'/docs/algorithm/%E6%8E%92%E5%BA%8F/on2/%E5%86%92%E6%B3%A1%E6%8E%92%E5%BA%8F/','title':"冒泡排序",'content':"冒泡排序 冒泡排序有三种写法：  一边比较一边向后两两交换，将最大值 / 最小值冒泡到最后一位； 经过优化的写法：使用一个变量记录当前轮次的比较是否发生过交换，如果没有发生交换表示已经有序，不再继续排序； 进一步优化的写法：除了使用变量记录当前轮次是否发生交换外，再使用一个变量记录上次发生交换的位置，下一轮排序时到达上次交换的位置就停止比较。  代码 package main import ( \u0026quot;fmt\u0026quot; ) func main() { values1 := []int{4, 93, 84, 85, 80, 37, 81, 93, 27, 12} fmt.Println(values1) // [4 93 84 85 80 37 81 93 27 12] MySort1(values1) fmt.Println(values1) // [4 12 27 37 80 81 84 85 93 93] values2 := []int{4, 93, 84, 85, 80, 37, 81, 93, 27, 12} fmt.Println(values2) // [4 93 84 85 80 37 81 93 27 12] MySort1(values2) fmt.Println(values2) // [4 12 27 37 80 81 84 85 93 93] values3 := []int{4, 93, 84, 85, 80, 37, 81, 93, 27, 12} fmt.Println(values3) // [4 93 84 85 80 37 81 93 27 12] MySort1(values3) fmt.Println(values3) // [4 12 27 37 80 81 84 85 93 93] } // 第一种排序 func MySort1(arr []int) { for i := 0; i \u0026lt; len(arr); i++ { for j := 0; j \u0026lt; len(arr) -i - 1; j++ { if arr[j+1] \u0026lt; arr[j] { arr[j],arr[j+1] = arr[j+1],arr[j] } } } } // 第二种排序 func MySort2(arr []int) { var swapped bool = true; for i := 0; i \u0026lt; len(arr); i++ { if !swapped { break; } swapped = false; for j := 0; j \u0026lt; len(arr) -i - 1; j++ { if arr[j+1] \u0026lt; arr[j] { arr[j],arr[j+1] = arr[j+1],arr[j] swapped = true; } } } } // 第三种排序 func MySort3(arr []int) { var swapped bool = true; var indexOfLastUnsortedElement int = len(arr) - 1; // 上次发生交换的位置 var swappedIndex int = -1; for swapped { swapped = false; for i := 0; i \u0026lt; indexOfLastUnsortedElement; i++ { if arr[i] \u0026gt; arr[i+1] { arr[i],arr[i+1] = arr[i+1],arr[i] // 表示发生了交换 swapped = true; // 更新交换的位置 swappedIndex = i; } } // 最后一个没有经过排序的元素的下标就是最后一次发生交换的位置 indexOfLastUnsortedElement = swappedIndex; } } "});index.add({'id':13,'href':'/docs/algorithm/%E5%9B%BE/','title':"图",'content':"图 "});index.add({'id':14,'href':'/docs/algorithm/%E5%A0%86/','title':"堆",'content':"堆 "});index.add({'id':15,'href':'/docs/algorithm/%E6%8E%92%E5%BA%8F/','title':"排序",'content':"排序 "});index.add({'id':16,'href':'/docs/jiagou/1/','title':"架构基础",'content':"架构定义 系统vs子系统定义  系统: 泛指由一群有关联的个体组成，根据某种规则运作，能完成个别元件不能单独完成的工作的群体。它的意思 是“总体”“整体”或“联盟”。\u0026ndash; 来自《维基百科》 子系统: 由一群有关联的个体所组成的系统，多半会是更大系统中的一部分。\u0026ndash; 来自《维基百科》  关联(一群有关联的个体) + 规则(个体之间按照规则运行) + 能力(系统能力超越个体能力) + 分层(自顶向下逐层分解)\n模块vs组件定义   软件模块:是一套一致而互相有紧密关连的软件组织。它分别包含了程序和数据结构两部分。现代软件开发往往利用模 块作为合成的单位。模块的接口表达了由该模块提供的功能和调用它时所需的元素。模块是可能分开被编写 的单位。这使它们可再用和允许人员同时协作、编写及研究不同的模块。\u0026ndash; 来自《维基百科》\n  软件组件:自包含的、可编程的、可重用的、与语言无关的软件单元，软件组件可以很容易被用于组装应用程序中。\u0026ndash; 来自《维基百科》\n  系统: ** 逻辑拆分 -\u0026gt; 模块(课程模块、成绩模块) -\u0026gt; 职责分离 ** 物理拆分 -\u0026gt; 组件(Nginx服务器、Mysql服务器) -\u0026gt; 单元复用\n  架构vs框架定义   软件框架: 通常指的是为了实现某个业界标准或完成特定基本任务的软件组件规范，也指为了实现某个软件组件规范时， 提供规范所要求之基础功能的软件产品。 \u0026ndash; 来自《维基百科》\n  软件架构: 指软件系统的“基础结构”，创造这些基础结构的准则，以及对这些结构的描述。\u0026ndash; 来自《维基百科》\n  软件框架（Framework）: 组件规范、软件产品\n  软件架构（Architecture）: 结构、准则、描述\n  重新定义架构 软件架构: 软件架构指软件系统的顶层结构，它定义了系统由哪些角色（Role）组成，角色之间的关系 （Relation）和运作规则（Rule）。 [4R架构 – Rank + Role + Relation + Rule]\n顶层结构Rank(架构是分层的) + 组成角色Role(系统包含哪些角色) + 角色关系Relation(角色之间的关系) + 运作规则Rule(角色如何协作完成系统功能)\n4R架构应用  1.架构师职责  确定层级 拆解角色 定义关系 设计规则   2.架构文档内容  指明层级 描述角色 定义关系 展现规则   3.如何学习架构  自顶向下学习 角色有哪些？ 角色关系如何 运作规则是什么？    思维导图    "});index.add({'id':17,'href':'/docs/vbox/%E9%85%8D%E7%BD%AE%E7%BD%91%E5%8D%A1/','title':"配置网卡",'content':"配置网卡 https://blog.csdn.net/weixin_42541479/article/details/118407951\n1、安装centos7的时候注意选择两个网卡 两个网卡分别为：\nnat(虚拟机访问互联网，使用10.0.2.x段)\nhost-only(虚拟机和主机互相通信，使用192.168.56.x段)\n在偏好设置里面设置网络。如下图配置：\n    2、配置网络    3、开机，进入 cd /etc/etc/sysconfig/network-scripts/ 目录 cd /etc/sysconfig/network-scripts/ ls   vi ifcfg-enp0s3   vi ifcfg-enp0s8   service network restart   4、验证    拷贝 "});index.add({'id':18,'href':'/docs/algorithm/%E5%9B%BE/2.%E5%B9%B6%E6%9F%A5%E9%9B%86/2.2.quick-union-%E7%9A%84%E5%B9%B6%E6%9F%A5%E9%9B%86/','title':"2.2.Quick Union 的「并查集」",'content':"2.2.Quick Union 的「并查集」 Quick Union 工作原理 //todo::\n为什么 Quick Union 比 Quick Find 更加高效？ 总体来说，Quick Union 是比 Quick Find 更加高效的。 //todo::\n伪代码 public class UnionFind { int root[]; public UnionFind(int size) { root = new int[size]; for (int i = 0; i \u0026lt; size; i++) { root[i] = i; } } public int find(int x) { while (x != root[x]) { x = root[x]; } return x; } public void union(int x, int y) { int rootX = find(x); int rootY = find(y); if (rootX != rootY) { root[rootY] = rootX; } }; public boolean connected(int x, int y) { return find(x) == find(y); } } // App.java // 测试样例 public class App { public static void main(String[] args) throws Exception { UnionFind uf = new UnionFind(10); // 1-2-5-6-7 3-8-9 4 uf.union(1, 2); uf.union(2, 5); uf.union(5, 6); uf.union(6, 7); uf.union(3, 8); uf.union(8, 9); System.out.println(uf.connected(1, 5)); // true System.out.println(uf.connected(5, 7)); // true System.out.println(uf.connected(4, 9)); // false // 1-2-5-6-7 3-8-9-4 uf.union(9, 4); System.out.println(uf.connected(4, 9)); // true } } 时间复杂度     UnionFind 构造函数 find 函数 union 函数 connected 函数     时间复杂度 O(N) O(H) O(H) O(H)    注：NN 为「图」中顶点的个数，HH 为「树」的高度。\n"});index.add({'id':19,'href':'/docs/algorithm/%E5%9B%BE/2.%E5%B9%B6%E6%9F%A5%E9%9B%86/','title':"2.并查集",'content':"2.并查集 如果给你一些顶点，并且告诉你每个顶点的连接关系，你如何才能快速的找出两个顶点是否具有连通性呢？ 如「图 5. 连通性问题」，该图给出了顶点与顶点之间的连接关系， 那么，我们如何让计算机快速定位 (0, 3) , (1, 5), (7, 8) 是否相连呢？此时我们就需要机智的「并查集」数据结构了。 很多地方也会称「并查集」为算法。  图5.连通性问题    「并查集」的主要作用是用来解决网络中的连通性。这里的「网络」可以是计算机的网络， 也可以是人际关系的网络等等。例如，你可以通过「并查集」来判定两个人是否来自同一个祖先。\n「并查集」常用术语  父节点：顶点的直接父亲节点。如「图5. 连通性问题」中，顶点 3 的父节点是 1；顶点 2 的父节点是 0；顶点 9 的父节点是自己本身 9。 根节点：没有父节点的节点，本身可以视为自己的父节点。如「图5. 连通性问题」中，顶点 3 和 2 的根节点都是 0；0 即是自己本身的父节点，也是自己的根节点；顶点 9 的根节点是自己本身 9。  「并查集」基本思想 //todo::\n「并查集」编程思想 //todo::\n「并查集」的两个重要函数  find 函数：找到给定顶点的根结点。如「图5. 连通性问题」中，find 函数需要找到顶点 3 的根结点是 0 。 union 函数：合并两个顶点，并将他们的根结点保持一致。如「图5. 连通性问题」中，如果我们需要将顶点 4 和 顶点 5 合并，那么顶点 4 和 顶点 5 至少需要保持根节点一致，也就是说 union 函数需要将顶点 4 和 顶点 5 的根结点修改为相同的根结点。  「并查集」的两个实现方式  Quick Find 实现方式：它指的是实现「并查集」时，find 函数时间复杂度很低为 O(1)O(1)，但对应的 union 函数就需要承担更多的责任，它的时间复杂度为 O(N)O(N)。 Quick Union 实现方式：它指的是实现「并查集」时，相对于 Quick Find 的实现方式，我们通过降低 union 函数的职责来提高它的效率，但同时，我们也增加了 find 函数的职责。  "});index.add({'id':20,'href':'/docs/kafka/2.%E6%B6%88%E6%81%AF%E7%B3%BB%E7%BB%9F%E5%8E%9F%E7%90%86/','title':"2.消息系统原理",'content':"2.消息系统原理 一个消息系统负责将数据从一个应用传递到另外一个应用，应用只需关注于数据，无需关注数据在两个 或多个应用间是如何传递的。\n点对点消息传递  在点对点消息系统中，消息持久化到一个队列中。此时，将有一个或多个消费者消费队列中的数 据。但是一条消息只能被消费一次。 当一个消费者消费了队列中的某条数据之后，该条数据则从消息队列中删除。 该模式即使有多个消费者同时消费数据，也能保证数据处理的顺序。 基于推送模型的消息系统，由消息代理记录消费状态。  消息代理将消息推送(push)到消费者后，标记这条消息为已经被消费，但是这种方式无法很 好地保证消费的处理语义。      发布订阅消息传递  在发布-订阅消息系统中，消息被持久化到一个topic中。 消费者可以订阅一个或多个topic，消费者可以消费该topic中所有的数据，同一条数据可以被多个 消费者消费，数据被消费后不会立马删除。 在发布-订阅消息系统中，消息的生产者称为发布者，消费者称为订阅者。 Kafka 采取拉取模型(Poll)，由自己控制消费速度，以及消费的进度，消费者可以按照任意的偏移 量进行消费。    "});index.add({'id':21,'href':'/docs/algorithm/%E5%9B%BE/3.%E5%9B%BE%E7%9A%84%E6%B7%B1%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2%E7%AE%97%E6%B3%95-/3.2.%E6%B7%B1%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2%E7%AE%97%E6%B3%95-%E9%81%8D%E5%8E%86%E4%B8%A4%E7%82%B9%E4%B9%8B%E9%97%B4%E6%89%80%E6%9C%89%E8%B7%AF%E5%BE%84/','title':"3.2.深度优先搜索算法-遍历两点之间所有路径",'content':"3.2.深度优先搜索算法-遍历两点之间所有路径 代码   "});index.add({'id':22,'href':'/docs/algorithm/%E6%8E%92%E5%BA%8F/onlogn/','title':"O(nlogn)",'content':"O(nlogn) "});index.add({'id':23,'href':'/docs/go/2.%E5%B9%B6%E5%8F%91/','title':"二、并发",'content':"二.并发 多路复用 select { case ret := \u0026lt;-retCh1: t.Logf(\u0026quot;result %s\u0026quot;, ret) case ret := \u0026lt;-retCh2: t.Logf(\u0026quot;result %s\u0026quot;, ret) default: t.Error(\u0026quot;no one returned\u0026quot;) } 如果执行到select时没有收到channel的消息的时候，如果有default就会执行default 超时 select { case ret := \u0026lt;-retCh1: t.Logf(\u0026quot;result %s\u0026quot;, ret) case \u0026lt;-time.After(time.Second * 1) // 超时 t.Error(\u0026quot;time out\u0026quot;) } channel的关闭与广播  向关闭的channel发送数据, 会导致panic v, ok \u0026lt;- ch; ok 为bool值, true表示正常接收, false表示通道关闭 所有的channel接收者都会在channel关闭时,立刻从阻塞等待中返回且上述ok值为false。这个广播机制被利用,进行向多个 订阅者同时发送信号。例如:退出信号 接收已经关闭的通道，将获取该通道类型的默认值  任务的取消 package cancel_task import ( \u0026quot;fmt\u0026quot; \u0026quot;testing\u0026quot; \u0026quot;time\u0026quot; ) func isCancelled(cancelChan chan struct{}) bool { select { case \u0026lt;-cancelChan: return true default: return false } } func cancel_1(cancelChan chan struct {}) { cancelChan \u0026lt;- struct {} { } } func cancel_2(cancelChan chan struct {}) { close(cancelChan) } func TestCancel(t *testing.T) { cancelChan := make(chan struct {}, 0) for i := 0; i \u0026lt; 5; i++ { go func(i int, cancelCh chan struct{}) { for { if isCancelled(cancelChan) { break } time.Sleep(time.Millisecond * 5) } fmt.Println(i, \u0026quot;Cancelled()\u0026quot;) }(i, cancelChan) } //cancel_1(cancelChan) // 此方法不可取 cancel_2(cancelChan) // 广播机制 time.Sleep(time.Millisecond * 1) } context与任务取消  根Context:通过context.Background() 创建 子 Context: context.WithCancel(parentContext) 创建  ctx, cancel := context.WithCancel(context.Background())   当前Context被取消时,基于他的子context都会被取消 接收取消通知 \u0026lt;-ctx.Done()  package cancel_task import ( \u0026quot;context\u0026quot; \u0026quot;fmt\u0026quot; \u0026quot;testing\u0026quot; \u0026quot;time\u0026quot; ) func isCancelled(ctx context.Context) bool { select { case \u0026lt;-ctx.Done(): return true default: return false } } func TestCancel(t *testing.T) { ctx, cancel := context.WithCancel(context.Background()) for i := 0; i \u0026lt; 5; i++ { go func(i int, ctx context.Context) { for { if isCancelled(ctx) { break } time.Sleep(time.Millisecond * 5) } fmt.Println(i, \u0026quot;Cancelled()\u0026quot;) }(i, ctx) } cancel() time.Sleep(time.Millisecond * 1) } 仅运行一次 sync.once\npackage once_test import ( \u0026quot;fmt\u0026quot; \u0026quot;sync\u0026quot; ) type SingletonObj struct { Id string } var once sync.Once var obj *SingletonObj func GetSingletonObj() *SingletonObj { once.Do(func() { fmt.Println(\u0026quot;Create singleton obj\u0026quot;) obj = \u0026amp;SingletonObj{} }) return obj } 仅需任意任务完成 package one_ok import ( \u0026quot;fmt\u0026quot; \u0026quot;runtime\u0026quot; \u0026quot;testing\u0026quot; \u0026quot;time\u0026quot; ) func runTask(id int) string { time.Sleep(10 * time.Millisecond) return fmt.Sprintf(\u0026quot;The result is from %d\u0026quot;, id) } func FirstResponse() string { numOfRunner := 10 ch := make(chan string, numOfRunner) // 使用buffer channel 防止协程泄露 for i := 0; i \u0026lt; numOfRunner; i++ { go func(i int) { ret := runTask(i) ch \u0026lt;- ret }(i) } return \u0026lt;-ch } func TestFirstResponse(t *testing.T) { t.Log(\u0026quot;Befor:\u0026quot;, runtime.NumGoroutine()) t.Log(FirstResponse()) time.Sleep(time.Second * 1) t.Log(\u0026quot;After:\u0026quot;, runtime.NumGoroutine()) } 所有任务都完成 package mul_ok import ( \u0026quot;fmt\u0026quot; \u0026quot;runtime\u0026quot; \u0026quot;testing\u0026quot; \u0026quot;time\u0026quot; ) func runTask(id int) string { time.Sleep(10 * time.Millisecond) return fmt.Sprintf(\u0026quot;The result is from %d\u0026quot;, id) } func AllResponse() string { numOfRunner := 10 ch := make(chan string, numOfRunner) // 使用buffer channel 防止协程泄露 for i := 0; i \u0026lt; numOfRunner; i++ { go func(i int) { ret := runTask(i) ch \u0026lt;- ret }(i) } finalRet := \u0026quot;\u0026quot; for j:=0;j\u0026lt; numOfRunner;j++ { finalRet += \u0026lt;-ch + \u0026quot;\\n\u0026quot; } return finalRet } func TestFirstResponse(t *testing.T) { t.Log(\u0026quot;Befor:\u0026quot;, runtime.NumGoroutine()) t.Log(AllResponse()) time.Sleep(time.Second * 1) t.Log(\u0026quot;After:\u0026quot;, runtime.NumGoroutine()) } 对象池 使用buffer channel实现对象池 package pool_test import ( \u0026quot;errors\u0026quot; \u0026quot;fmt\u0026quot; \u0026quot;testing\u0026quot; \u0026quot;time\u0026quot; ) type ReusableObj struct { } type ObjPool struct { bufChan chan *ReusableObj } func NewObjPool(numOfObj int) *ObjPool { objPool := ObjPool {} objPool.bufChan = make(chan * ReusableObj, numOfObj) for i := 0; i \u0026lt; numOfObj; i++ { objPool.bufChan \u0026lt;- \u0026amp;ReusableObj{ } } return \u0026amp;objPool } func (p *ObjPool) GetObj(timeout time.Duration) (*ReusableObj, error) { select { case ret := \u0026lt;- p.bufChan: return ret, nil case \u0026lt;-time.After(timeout): return nil, errors.New(\u0026quot;time out\u0026quot;) } } func (p *ObjPool) ReleaseObj(obj *ReusableObj) error { select { case p.bufChan \u0026lt;- obj: return nil default: return errors.New(\u0026quot;overflow\u0026quot;) } } func TestObjPool(t *testing.T) { pool := NewObjPool(10) for i := 0; i \u0026lt; 11; i++ { if v, err := pool.GetObj(time.Second + 1); err != nil { t.Error(err) } else { fmt.Printf(\u0026quot;%T\\n\u0026quot;, v) if err := pool.ReleaseObj(v); err != nil { t.Error(err) } } } } sync.Pool对象缓存  尝试从私有对象获取 私有对象不存在，尝试从当前Processor的共享池获取 如果当前Processor共享池也是空的，那么就尝试去其他Processor的共享池获取 如果所有子池都是空的，最后就用用户指定的New函数产生一个新的对象返回  私有对象: 协程安全\n共享池: 协程不安全\nsync.Pool对象的放回  如果私有对象不存在则保存为私有对象 如果私有对象存在，放入当前Processor子池的共享池中  pool := \u0026amp;sync.Pool{ New: func() interface{} { return 0 }, } arry := pool.Get().(int) ... pool.Put(10) sync.Pool对象的生命周期  GC会清除sync.pool缓存的对象 对象的缓存有效期为下一次GC之前  sync.Pool总结  适用于通过复用,降低复杂对象的创建和GC代价 协程安全, 会有锁的开销 生命周期受GC影响,不适合于做 连接池等，需要自己管理生命周期的资源的池化  "});index.add({'id':24,'href':'/docs/vbox/%E6%8B%B7%E8%B4%9D/','title':"拷贝",'content':"拷贝    修改配置 /etc/sysconfig/network-scripts/ifcfg-enp0s3 /etc/sysconfig/network-scripts/ifcfg-enp0s8 注意: 参考配置网卡里面的配置\n"});index.add({'id':25,'href':'/docs/algorithm/%E6%8E%92%E5%BA%8F/on2/%E9%80%89%E6%8B%A9%E6%8E%92%E5%BA%8F/','title':"选择排序",'content':"选择排序 选择排序的思想是：双重循环遍历数组，每经过一轮比较，找到最小元素的下标，将其交换至首位。\npackage main import \u0026quot;fmt\u0026quot; func main() { values1 := []int{4, 93, 84, 85, 80, 37, 81, 93, 27, 12} fmt.Println(values1) // [4 93 84 85 80 37 81 93 27 12] SelectSort(values1) fmt.Println(values1) // [4 12 27 37 80 81 84 85 93 93] values2 := []int{4, 93, 84, 85, 80, 37, 81, 93, 27, 12} fmt.Println(values2) // [4 93 84 85 80 37 81 93 27 12] SelectSort(values2) fmt.Println(values2) // [4 12 27 37 80 81 84 85 93 93] } func SelectSort(values []int) { for i := 0; i \u0026lt; len(values); i++ { min := i for j := len(values) - 1; j \u0026gt; i; j-- { if values[j] \u0026lt; values[min] { min = j } } values[i], values[min] = values[min], values[i] } } func SelectSort2(values []int) { var minIndex int var maxIndex int // i 只需要遍历一半 for i := 0; i \u0026lt; len(values) / 2; i++ { minIndex = i maxIndex = i for j := i + 1; j \u0026lt; len(values) -1; j++ { if values[minIndex] \u0026gt; values[j] { // 记录最小值的下标 minIndex = j } if values[maxIndex] \u0026lt; values[j] { // 记录最大值的下标 maxIndex = j } } // 如果 minIndex 和 maxIndex 都相等，那么他们必定都等于 i，且后面的所有数字都与 arr[i] 相等，此时已经排序完成 if minIndex == maxIndex { break; } // 将最小元素交换至首位 values[minIndex], values[i] = values[i], values[minIndex] // 如果最大值的下标刚好是 i，由于 arr[i] 和 arr[minIndex] 已经交换了，所以这里要更新 maxIndex 的值。 if maxIndex == i { maxIndex = minIndex } // 将最大元素交换至末尾 lastIndex := len(values) -1 - i; values[maxIndex], values[lastIndex] = values[lastIndex], values[maxIndex] } } "});index.add({'id':26,'href':'/docs/algorithm/%E5%9B%BE/2.%E5%B9%B6%E6%9F%A5%E9%9B%86/2.3.%E6%8C%89%E7%A7%A9%E5%90%88%E5%B9%B6%E7%9A%84%E5%B9%B6%E6%9F%A5%E9%9B%86/','title':"2.3.按秩合并的「并查集」",'content':"2.3.按秩合并的「并查集」 小伙伴看到这里的时候，我们其实已经实现了 2 种「并查集」。但它们都有一个很大的缺点，这个缺点就是通过 union 函数连接顶点之后，可能所有顶点连成一条线形成「图 5. 一条线的图」，这就是我们 find 函数在最坏的情况下的样子。那么我们有办法解决吗？\n当然，伟大的科学家已经给出了解决方案，就是按秩合并。这里的「秩」可以理解为「秩序」。之前我们在 union 的时候，我们是随机选择 x 和 y 中的一个根节点/父节点作为另一个顶点的根节点。但是在「按秩合并」中，我们是按照「某种秩序」选择一个父节点。\n这里的「秩」指的是每个顶点所处的高度。我们每次 union 两个顶点的时候，选择根节点的时候不是随机的选择某个顶点的根节点，而是将「秩」大的那个根节点作为两个顶点的根节点，换句话说，我们将低的树合并到高的树之下，将高的树的根节点作为两个顶点的根节点。这样，我们就避免了所有的顶点连成一条线，这就是按秩合并优化的「并查集」。  图5.一条线的图    伪代码 // UnionFind.class public class UnionFind { int root[]; int rank[]; public UnionFind(int size) { root = new int[size]; rank = new int[size]; for (int i = 0; i \u0026lt; size; i++) { root[i] = i; rank[i] = 1; } } public int find(int x) { while (x != root[x]) { x = root[x]; } return x; } public void union(int x, int y) { int rootX = find(x); int rootY = find(y); if (rootX != rootY) { if (rank[rootX] \u0026gt; rank[rootY]) { root[rootY] = rootX; } else if (rank[rootX] \u0026lt; rank[rootY]) { root[rootX] = rootY; } else { root[rootY] = rootX; rank[rootX] += 1; } } }; public boolean connected(int x, int y) { return find(x) == find(y); } } // App.java // 测试样例 public class App { public static void main(String[] args) throws Exception { UnionFind uf = new UnionFind(10); // 1-2-5-6-7 3-8-9 4 uf.union(1, 2); uf.union(2, 5); uf.union(5, 6); uf.union(6, 7); uf.union(3, 8); uf.union(8, 9); System.out.println(uf.connected(1, 5)); // true System.out.println(uf.connected(5, 7)); // true System.out.println(uf.connected(4, 9)); // false // 1-2-5-6-7 3-8-9-4 uf.union(9, 4); System.out.println(uf.connected(4, 9)); // true } } 时间复杂度     UnionFind 构造函数 find 函数 union 函数 connected 函数     时间复杂度 O(N) O(logN) O(logN) O(logN)    注：N 为「图」中顶点的个数。\n"});index.add({'id':27,'href':'/docs/kafka/3.kafka%E7%AE%80%E4%BB%8B/','title':"3.kafka简介",'content':"kafka简介   官网： http://kafka.apache.org\n  Kafka是由Apache软件基金会开发的一个开源流处理平台，由Scala和Java编写。Kafka是一种高吞 吐量的分布式发布订阅消息系统，它可以处理消费者在网站中的所有动作流数据。    设计目标  以时间复杂度为O(1)的方式提供消息持久化能力，即使对TB级以上数据也能保证常数时间的访问 性能。 高吞吐率。即使在非常廉价的商用机器上也能做到单机支持每秒100K条消息的传输。 支持Kafka Server间的消息分区，及分布式消费，同时保证每个partition内的消息顺序传输。 同时支持离线数据处理和实时数据处理。 支持在线水平扩展  Kafka的优点   解耦\n在项目启动之初来预测将来项目会碰到什么需求，是极其困难的。消息系统在处理过程中间插入了一个 隐含的、基于数据的接口层，两边的处理过程都要实现这一接口。这允许你独立的扩展或修改两边的处 理过程，只要确保它们遵守同样的接口约束。\n  冗余\n有些情况下，处理数据的过程会失败。除非数据被持久化，否则将造成丢失。消息队列把数据进行持久 化直到它们已经被完全处理，通过这一方式规避了数据丢失风险。许多消息队列所采用的\u0026quot;插入-获取-删 除\u0026quot;范式中，在把一个消息从队列中删除之前，需要你的处理系统明确的指出该消息已经被处理完毕， 从而确保你的数据被安全的保存直到你使用完毕。\n  扩展性\n因为消息队列解耦了你的处理过程，所以增大消息入队和处理的频率是很容易的，只要另外增加处理过 程即可。不需要改变代码、不需要调节参数。扩展就像调大电力按钮一样简单。\n  灵活性\u0026amp;峰值处理能力\n在访问量剧增的情况下，应用仍然需要继续发挥作用，但是这样的突发流量并不常见；如果为以能处理 这类峰值访问为标准来投入资源随时待命无疑是巨大的浪费。使用消息队列能够使关键组件顶住突发的 访问压力，而不会因为突发的超负荷的请求而完全崩溃。\n  可恢复性\n系统的一部分组件失效时，不会影响到整个系统。消息队列降低了进程间的耦合度，所以即使一个处理 消息的进程挂掉，加入队列中的消息仍然可以在系统恢复后被处理。\n  顺序保证\n在大多使用场景下，数据处理的顺序都很重要。大部分消息队列本来就是排序的，并且能保证数据会按 照特定的顺序来处理。Kafka保证一个Partition内的消息的有序性。\n  缓冲\n在任何重要的系统中，都会有需要不同的处理时间的元素。例如，加载一张图片比应用过滤器花费更少 的时间。消息队列通过一个缓冲层来帮助任务最高效率的执行———写入队列的处理会尽可能的快速。 该缓冲有助于控制和优化数据流经过系统的速度。\n  异步通信 很多时候，用户不想也不需要立即处理消息。消息队列提供了异步处理机制，允许用户把一个消息放入 队列，但并不立即处理它。想向队列中放入多少消息就放多少，然后在需要的时候再去处理它们。\n  "});index.add({'id':28,'href':'/docs/algorithm/%E5%9B%BE/3.%E5%9B%BE%E7%9A%84%E6%B7%B1%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2%E7%AE%97%E6%B3%95-/','title':"3.「图」的深度优先搜索算法",'content':"3.「图」的深度优先搜索算法 在前面的「并查集」数据结构中，大家已经知道如何检查两个顶点之间的连通性。那如果给你一个「图」，你该如何找出它所有的顶点呢？以及你又如何找出它两个顶点之间的所有路径呢？此时，「深度优先搜索」算法就可以登场了。如「图6. 无向图」所示，它的所有顶点分别为[A, C, D, B, E]。给定顶点 A 和 B， 它们之间有两条路径，一条路径为[A, C, D, B]，另一条路径为[A, E, B]。  图6.无向图    「深度优先搜索」（又称「Depth First Search」，简称「DFS」）算法在「图」中主要用途：\n 遍历「图」中所有顶点； 遍历「图」中任意两点之间的所有路径。  "});index.add({'id':29,'href':'/docs/algorithm/%E6%8E%92%E5%BA%8F/on/','title':"O(n)",'content':"O(n) "});index.add({'id':30,'href':'/docs/go/3.%E6%B5%8B%E8%AF%95/','title':"三、测试",'content':"三、测试 单元测试 func square(i int) int { return i * i } func TestSquare(t *testing.T) { inputs := [...]int{1, 2, 3} expected := [...]int{1, 4, 10} for i := 0; i \u0026lt; len(inputs); i++{ ret := square(inputs[i]) if ret != expected[i] { t.Errorf(\u0026quot;input is %d, the expected is %d, \u0026quot; + \u0026quot;the actual is %d\u0026quot;, inputs[i], expected[i], ret) } } } 内置单元测试框架  Fail,Error:该测试失败,该测试继续, 其他测试继续执行 FailNow,Fatal:该测试失败,该测试终止，其他测试继续执行  func TestErrorInCode(t *testing.T) { fmt.Println(\u0026quot;Start\u0026quot;) t.Error(\u0026quot;Error\u0026quot;) fmt.Println(\u0026quot;End\u0026quot;) } //结果: //Start //demo_test.go:26: Error //End func TestFailInCode(t *testing.T) { fmt.Println(\u0026quot;Start\u0026quot;) t.Fatal(\u0026quot;Fatal\u0026quot;) fmt.Println(\u0026quot;End\u0026quot;) } //结果: //Start //demo_test.go:35: Fatal   代码覆盖率\ngo test -v -cover\n  断言\ngo get -u github.com/stretchr/testify/assert\n  Benchmark func BenchmarkConcatStringByAdd(b *testing.B) { // 与性能测试无关的代码 b.ResetTimer() for i := 0; i \u0026lt; b.N; i++ { // 测试代码 } b.StopTimer() // 与性能测试无关的代码 } go test -bench=. -benchmem\nBDD in Go 项目网站 https://github.com/smartystreets/goconvey\n安装 go get -u github.com/smartystreets/goconvey\n启动 WEB UI $GOPATH/bin/goconvey\n"});index.add({'id':31,'href':'/docs/algorithm/%E6%8E%92%E5%BA%8F/on2/%E6%8F%92%E5%85%A5%E6%8E%92%E5%BA%8F/','title':"插入排序",'content':"插入排序 插入排序有两种写法：  交换法：在新数字插入过程中，不断与前面的数字交换，直到找到自己合适的位置。 移动法：在新数字插入过程中，与前面的数字不断比较，前面的数字不断向后挪出位置，当新数字找到自己的位置后，插入一次即可。  "});index.add({'id':32,'href':'/docs/algorithm/%E5%9B%BE/2.%E5%B9%B6%E6%9F%A5%E9%9B%86/2.4.%E8%B7%AF%E5%BE%84%E5%8E%8B%E7%BC%A9%E4%BC%98%E5%8C%96%E7%9A%84%E5%B9%B6%E6%9F%A5%E9%9B%86/','title':"2.4.路径压缩优化的「并查集」",'content':"2.4.路径压缩优化的「并查集」 从前面的「并查集」实现方式中，我们不难看出，要想找到一个元素的根节点，需要沿着它的父亲节点的足迹一直遍历下去，直到找到它的根节点为止。如果下次再查找同一个元素的根节点，我们还是要做相同的操作。那我们有没有什么办法将它升级优化下呢？\n答案是可以的！如果我们在找到根节点之后，将所有遍历过的元素的父节点都改成根节点，那么我们下次再查询到相同元素的时候，我们就仅仅只需要遍历两个元素就可以找到它的根节点了，这是非常高效的实现方式。那么问题来了，我们如何将所有遍历过的元素的父节点都改成根节点呢？这里就要拿出「递归」算法了。这种优化我们称之为「路径压缩」优化，它是对 find 函数的一种优化。\n伪代码 // UnionFind.class public class UnionFind { int root[]; public UnionFind(int size) { root = new int[size]; for (int i = 0; i \u0026lt; size; i++) { root[i] = i; } } public int find(int x) { if (x == root[x]) { return x; } return root[x] = find(root[x]); } public void union(int x, int y) { int rootX = find(x); int rootY = find(y); if (rootX != rootY) { root[rootY] = rootX; } }; public boolean connected(int x, int y) { return find(x) == find(y); } } // App.java // 测试样例 public class App { public static void main(String[] args) throws Exception { UnionFind uf = new UnionFind(10); // 1-2-5-6-7 3-8-9 4 uf.union(1, 2); uf.union(2, 5); uf.union(5, 6); uf.union(6, 7); uf.union(3, 8); uf.union(8, 9); System.out.println(uf.connected(1, 5)); // true System.out.println(uf.connected(5, 7)); // true System.out.println(uf.connected(4, 9)); // false // 1-2-5-6-7 3-8-9-4 uf.union(9, 4); System.out.println(uf.connected(4, 9)); // true } } 时间复杂度     UnionFind 构造函数 find 函数 union 函数 connected 函数     时间复杂度 O(N) O(logN) O(logN) O(logN)    注：N 为「图」中顶点的个数。\n"});index.add({'id':33,'href':'/docs/kafka/4.kafka%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84/','title':"4.kafka系统架构",'content':"4.kafka系统架构  Broker  Kafka 集群包含一个或多个服务器，服务器节点称为broker。  Topic (类似表)  每条发布到Kafka集群的消息都有一个类别，这个类别被称为Topic。 类似于数据库的表名或者ES的Index 物理上不同Topic的消息分开存储 逻辑上一个Topic的消息虽然保存于一个或多个broker上但用户只需指定消息的Topic即可生产或消 费数据而不必关心数据存于何处） 创建流程  1.controller在ZooKeeper的/brokers/topics节点上注册watcher，当topic被创建， 则 controller会通过watch得到该topic的partition/replica分配。 2.controller从/brokers/ids读取当前所有可用的broker列表，对于set_p中的每一个 partition： 2.1从分配给该partition的所有replica（称为AR）中任选一个可用的broker作为新的 leader， 并将AR设置为新的ISR 2.2将新的leader和ISR写 入/brokers/topics/[topic]/partitions/[partition]/state 3.controller通过RPC向相关的broker发送LeaderAndISRRequest。  删除流程  1.controller在zooKeeper的/brokers/topics节点上注册watcher，当topic被删除， 则controller会通过watch得到该topic的partition/replica分配。 2.若delete.topic.enable=false，结束；否则controller注册在/admin/delete_topics上 的watch被fire, controller通过回调向对应的broker发送StopReplicaRequest。 Partition (分区表的)   topic中的数据分割为一个或多个partition。 每个topic至少有一个partition,当生产者产生数据的时候，根据分配策略,选择分区,然后将消息追 加到指定的分区的末尾（队列）  ## Partation数据路由规则 1. 指定了 patition，则直接使用； 2. 未指定 patition 但指定 key，通过对 key 的 value 进行hash 选出一个 patition 3. patition 和 key 都未指定，使用轮询选出一个 patition。  每条消息都会有一个自增的编号  标识顺序 用于标识消息的偏移量   每个partition中的数据使用多个segment文件存储。 partition中的数据是有序的，不同partition间的数据丢失了数据的顺序。 如果topic有多个partition，消费数据时就不能保证数据的顺序。严格保证消息的消费顺序的场景 下，需要将partition数目设为1。  Leader (读写) 每个partition有多个副本，其中有且仅有一个作为Leader，Leader是当前负责数据的读写的 partition。\n1. producer 先从 zookeeper 的 \u0026quot;/brokers/.../state\u0026quot; 节点找到该 partition 的 leader 2. producer 将消息发送给该 leader 3. leader 将消息写入本地 log 4. followers 从 leader pull 消息，写入本地 log 后 leader 发送 ACK 5. leader 收到所有 ISR 中的 replica 的 ACK 后，增加 HW（high watermark， 最后 commit 的 offset） 并向 producer 发送 ACK Follower (只备份)  Follower跟随Leader，所有写请求都通过Leader路由，数据变更会广播给所有Follower， Follower与Leader保持数据同步。 如果Leader失效，则从Follower中选举出一个新的Leader。 当Follower挂掉、卡住或者同步太慢，leader会把这个follower从“in sync replicas”（ISR）列表中 删除，重新创建一个Follower。  replication (Follower的另外一个叫法)  数据会存放到topic的partation中，但是有可能分区会损坏 我们需要对分区的数据进行备份（备份多少取决于你对数据的重视程度） 我们将分区的分为Leader(1)和Follower(N)  Leader负责写入和读取数据 Follower只负责备份 保证了数据的一致性   备份数设置为N，表示主+备=N(参考HDFS)  ## Kafka 分配 Replica 的算法如下 1. 将所有 broker（假设共 n 个 broker）和待分配的 partition 排序 2. 将第 i 个 partition 分配到第（i mod n）个 broker 上 3. 将第 i 个 partition 的第 j 个 replica 分配到第（(i + j) mode n）个 broker 上   producer  生产者即数据的发布者，该角色将消息发布到Kafka的topic中。 broker接收到生产者发送的消息后，broker将该消息追加到当前用于追加数据的segment文件 中。 生产者发送的消息，存储到一个partition中，生产者也可以指定数据存储的partition。  consumer  消费者可以从broker中读取数据。消费者可以消费多个topic中的数据。 kafka 提供了两套 consumer API：  1. The high-level Consumer API 2. The SimpleConsumer API  high-level consumer API 提供了一个从 kafka 消费数据的高层抽象，而 SimpleConsumer API 则 需要开发人员更多地关注细节。    Consumer Group  每个Consumer属于一个特定的Consumer Group（可为每个Consumer指定group name，若不 指定group name则属于默认的group）。 将多个消费者集中到一起去处理某一个Topic的数据，可以更快的提高数据的消费能力 整个消费者组共享一组偏移量(防止数据被重复读取)，因为一个Topic有多个分区    offset偏移量  可以唯一的标识一条消息 偏移量决定读取数据的位置，不会有线程安全的问题，消费者通过偏移量来决定下次读取的消息 消息被消费之后，并不被马上删除，这样多个业务就可以重复使用kafka的消息 我们某一个业务也可以通过修改偏移量达到重新读取消息的目的,偏移量由用户控制 消息最终还是会被删除的，默认生命周期为1周（7*24小时）  Zookeeper  kafka 通过 zookeeper 来存储集群的 meta 信息。      "});index.add({'id':34,'href':'/docs/algorithm/%E5%9B%BE/4.%E5%9B%BE%E7%9A%84%E5%B9%BF%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2%E7%AE%97%E6%B3%95/','title':"4.「图」的广度优先搜索算法",'content':"4.「图」的广度优先搜索算法 既然我们之前已经提及了「深度优先搜索」算法了，那么作为它的兄弟算法「广度优先遍历」算法，我们就不得不提了。「广度优先搜索」算法不仅可以遍历「图」的所有顶点，也可以遍历两个顶点的所有路径。但是，「广度优先搜索」最高效的用途是：当在 权重相等且均为正数的「图」 中，它可以快速的找到两点之间的最短路径。\n虽然「深度优先搜索」算法也可以针对权重相等均且为正数的「图」找出两点之间的最短路径，但它需要先找出两点之间的所有路径之后，才可以求出最短路径。但是对于「广度优先搜索」，在大多数情况下，它可以不用找出所有路径，就能取出两点之间的最短路径。除非，最短路径出现在最后一条遍历的路径上，这种情况下，「广度优先搜索」也是遍历出了所有路径后，才取出的最短路径。\n如「图7. 无向图」所示，它的所有顶点分别为[A, C, D, B, E]。给定顶点 A 和 B， 它们之间有两条路径，一条路径为[A, C, D, B]，另一条路径为[A, E, B]。其中，[A, E, B]是顶点 A 和 B 之间的最短路径。\n 图7.无向图    「广度优先遍历」（又称「Breath First Search」，简称「BFS」）算法在「图」中主要用途：\n 遍历「图」中所有顶点； 针对 权重相等且均为正数的「图」，快速找出两点之间的最短路径。  "});index.add({'id':35,'href':'/docs/go/4.%E5%8F%8D%E5%B0%84%E5%92%8C%E4%B8%8D%E5%AE%89%E5%85%A8%E7%BC%96%E7%A8%8B/','title':"四、反射和不安全编程",'content':"四、反射和不安全编程 反射 reflect.TypeOf vs reflect.ValueOf  reflect.TypeOf 返回类型(reflect.Type) reflect.ValueOf 返回值(reflect.Value) 可以从reflect.Value获取类型 通过kind来判断类型  判断类型-Kind() const ( Invalid constant.Kind = iota Bool Int Int8 Int16 Int32 Int64 Uint Uint8 Uint16 Uint32 Uint64 ... ) demo func CheckType(v interface{}) { t := reflect.TypeOf(v) switch t.Kind() { case reflect.Float32, reflect.Float64 : fmt.Println(\u0026quot;Float\u0026quot;) case reflect.Int, reflect.Int8, reflect.Int16, reflect.Int32: fmt.Println(\u0026quot;Integer\u0026quot;) default: fmt.Println(\u0026quot;Unknown\u0026quot;, t) } } func TestCheckType(t *testing.T) { var f float64 = 12 CheckType(f) } 利用反射编写灵活的代码 按名字访问结构的成员 reflect.ValueOf(*e).FieldByName(\u0026quot;Name\u0026quot;)  按名字访问结构的方法 reflect.ValueOf(e).MethodByName(\u0026quot;UpdateAge\u0026quot;).Call([]reflect.Value {reflect.ValueOf(1)})  type Employee struct { EmployeeID string Name string `format:\u0026quot;normal\u0026quot;` Age int } func (e *Employee) UpdateAge(newVal int) { e.Age = newVal } type Customer struct { CookieID string Name string Age int } func TestInvokeByName(t *testing.T) { e := \u0026amp;Employee{\u0026quot;1\u0026quot;, \u0026quot;Mike\u0026quot;, 30} // 按名称获取成员 t.Logf(\u0026quot;Name: value(%[1]v), Type(%[1]T) \u0026quot;, reflect.ValueOf(*e).FieldByName(\u0026quot;Name\u0026quot;)) if nameField, ok := reflect.TypeOf(*e).FieldByName(\u0026quot;Name\u0026quot;); !ok { t.Error(\u0026quot;Failed to get 'Name' field.\u0026quot;) } else { t.Log(\u0026quot;Tag:format\u0026quot;, nameField.Tag.Get(\u0026quot;format\u0026quot;)) } reflect.ValueOf(e).MethodByName(\u0026quot;UpdateAge\u0026quot;).Call([]reflect.Value {reflect.ValueOf(1)}) t.Log(\u0026quot;Updated Age:\u0026quot;, e) } struct Tag type BasicInfo struct { Name string `json:\u0026quot;name\u0026quot;` Age int `json:\u0026quot;age\u0026quot;` } `json:\u0026quot;name\u0026quot;` 和 `json:\u0026quot;age\u0026quot;` 为struct Tag 访问StructTag if nameField, ok := reflect.TypeOf(*e).FieldByName(\u0026quot;Name\u0026quot;); !ok { t.Error(\u0026quot;Failed to get 'Name' field.\u0026quot;) } else { t.Log(\u0026quot;Tag:format\u0026quot;, nameField.Tag.Get(\u0026quot;format\u0026quot;)) } Reflect.Type 和 Reflect.Value 都有 FieldByName 方法, 注意他们的区别 万能程序 DeepEqual 比较切片和map\nfunc TestDeepEqual(t *testing.T) { a := map[int]string{1:\u0026quot;one\u0026quot;, 2:\u0026quot;two\u0026quot;, 3:\u0026quot;three\u0026quot;} b := map[int]string{1:\u0026quot;one\u0026quot;, 2:\u0026quot;two\u0026quot;, 3:\u0026quot;three\u0026quot;} //t.Log(a == b) // invalid operation: a == b (map can only be compared to nil) t.Log(reflect.DeepEqual(a, b)) s1 := []int{1, 2, 3} s2 := []int{1, 2, 3} s3 := []int{2, 3, 1} t.Log(\u0026quot;s1 == s2\u0026quot;, reflect.DeepEqual(s1, s2)) t.Log(\u0026quot;s1 == s3\u0026quot;, reflect.DeepEqual(s1, s3)) } 关于\u0026quot;反射\u0026quot;你应该知道的  提高了程序的灵活性 降低了程序的可读性 降低了程序的性能  type Employee struct { EmployeeID string Name string `format:\u0026quot;normal\u0026quot;` Age int } func (e *Employee) UpdateAge(newVal int) { e.Age = newVal } type Customer struct { CookieID string Name string Age int } func fillBySettings(st interface{}, settings map[string]interface{}) error { if reflect.TypeOf(st).Kind() != reflect.Ptr { if reflect.TypeOf(st).Elem().Kind() != reflect.Struct { return errors.New(\u0026quot;the first param should be a pointer to the struct type\u0026quot;) } } if settings == nil { return errors.New(\u0026quot;settings is nil.\u0026quot;) } var ( field reflect.StructField ok bool ) for k, v := range settings { if field, ok = (reflect.ValueOf(st)).Elem().Type().FieldByName(k); !ok { continue } if field.Type == reflect.TypeOf(v) { vstr := reflect.ValueOf(st) vstr = vstr.Elem() vstr.FieldByName(k).Set(reflect.ValueOf(v)) } } return nil } func TestFillNameAndAge(t *testing.T) { settings := map[string]interface{}{\u0026quot;Name\u0026quot;:\u0026quot;Mike\u0026quot;, \u0026quot;Age\u0026quot;:10} e := Employee{} if err := fillBySettings(\u0026amp;e, settings); err != nil { t.Fatal(err) } t.Log(e) c := new(Customer) if err := fillBySettings(c, settings); err != nil { t.Fatal(err) } t.Log(*c) } 不安全编程 \u0026ldquo;不安全\u0026quot;行为的危险性 i := 10 f := *(*float64)(unsafe.Point(\u0026amp;i)) func TestAtomic(t *testing.T) { var shareBufferPtr unsafe.Pointer writeDataFn := func() { data := []int{} for i := 0; i \u0026lt; 100; i++ { data = append(data, i) } atomic.StorePointer(\u0026amp;shareBufferPtr, unsafe.Pointer(\u0026amp;data)) } readDataFn := func() { data := atomic.LoadPointer(\u0026amp;shareBufferPtr) fmt.Println(data, *(*[]int)(data)) } var wg sync.WaitGroup writeDataFn() for i := 0; i \u0026lt; 100; i++ { wg.Add(i) go func() { for i := 0; i \u0026lt; 100; i++ { writeDataFn() time.Sleep(time.Millisecond * 100) } wg.Done() }() wg.Add(1) go func() { for i := 0; i \u0026lt; 100; i++{ readDataFn() time.Sleep(time.Millisecond * 100) } wg.Done() }() } } "});index.add({'id':36,'href':'/docs/algorithm/%E5%9B%BE/2.%E5%B9%B6%E6%9F%A5%E9%9B%86/2.5.%E5%9F%BA%E4%BA%8E%E8%B7%AF%E5%BE%84%E5%8E%8B%E7%BC%A9%E7%9A%84%E6%8C%89%E7%A7%A9%E5%90%88%E5%B9%B6%E4%BC%98%E5%8C%96%E7%9A%84%E5%B9%B6%E6%9F%A5%E9%9B%86/','title':"2.5.基于路径压缩的按秩合并优化的「并查集」",'content':"2.5.基于路径压缩的按秩合并优化的「并查集」 这个优化就是将「路径压缩优化」和「按秩合并优化」合并后形成的「并查集」的实现方式。\n伪代码 // UnionFind.class public class UnionFind { int root[]; // 添加了 rank 数组来记录每个顶点的高度，也就是每个顶点的「秩」 int rank[]; public UnionFind(int size) { root = new int[size]; rank = new int[size]; for (int i = 0; i \u0026lt; size; i++) { root[i] = i; rank[i] = 1; // 一开始每个顶点的初始「秩」为1，因为它们只有自己本身的一个顶点。 } } // 此处的 find 函数与路径压优化缩版本的 find 函数一样。 public int find(int x) { if (x == root[x]) { return x; } return root[x] = find(root[x]); } // 按秩合并优化的 union 函数 public void union(int x, int y) { int rootX = find(x); int rootY = find(y); if (rootX != rootY) { if (rank[rootX] \u0026gt; rank[rootY]) { root[rootY] = rootX; } else if (rank[rootX] \u0026lt; rank[rootY]) { root[rootX] = rootY; } else { root[rootY] = rootX; rank[rootX] += 1; } } }; public boolean connected(int x, int y) { return find(x) == find(y); } } // App.java // 测试样例 public class App { public static void main(String[] args) throws Exception { UnionFind uf = new UnionFind(10); // 1-2-5-6-7 3-8-9 4 uf.union(1, 2); uf.union(2, 5); uf.union(5, 6); uf.union(6, 7); uf.union(3, 8); uf.union(8, 9); System.out.println(uf.connected(1, 5)); // true System.out.println(uf.connected(5, 7)); // true System.out.println(uf.connected(4, 9)); // false // 1-2-5-6-7 3-8-9-4 uf.union(9, 4); System.out.println(uf.connected(4, 9)); // true } } 时间复杂度     UnionFind 构造函数 find 函数 union 函数 connected 函数     时间复杂度 O(N) O(⍺(N)) O(⍺(N)) O(⍺(N))    注：N 为「图」中顶点的个数。\n"});index.add({'id':37,'href':'/docs/kafka/5.kafka%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/','title':"5.kafka环境搭建",'content':"5.kafka环境搭建 "});index.add({'id':38,'href':'/docs/algorithm/%E5%9B%BE/5.%E6%9C%80%E5%B0%8F%E7%94%9F%E6%88%90%E6%A0%91%E7%9B%B8%E5%85%B3%E7%AE%97%E6%B3%95/','title':"5.最小生成树相关算法",'content':"5.最小生成树相关算法 "});index.add({'id':39,'href':'/docs/go/5.%E4%BE%9D%E8%B5%96%E7%AE%A1%E7%90%86go-mod/','title':"五、依赖管理go mod",'content':"五、依赖管理go mod  由go命令统一的管理,用户不必关心目录结构 初始化: go mod init 增加依赖: go get 更新依赖: go get [@v\u0026hellip;], go mod tidy 将旧项目迁移到go mod: go mod init, go build ./\u0026hellip;  Go mod下如何引用本项目的包呢？ 大家只要记住这个公式即可：\nimport的路径 = go.mod下的module name + 包相对于go.mod的相对目录 ## go编译多个 go build ./... 编译当前和子目录下的main文件，不产生二机制文件 go install ./... 编译当前和子目录下的main文件，产生二机制文件。在 GOPATH目录的bin目录下 "});index.add({'id':40,'href':'/docs/algorithm/%E5%9B%BE/2.%E5%B9%B6%E6%9F%A5%E9%9B%86/2.6.%E5%B9%B6%E6%9F%A5%E9%9B%86%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E6%80%BB%E7%BB%93/','title':"2.6.「并查集」数据结构总结",'content':"2.6.「并查集」数据结构总结 在「并查集」数据结构中，其中心思想是将所有连接的顶点，无论是直接连接还是间接连接，都将他们指向同一个父节点或者根节点。此时，如果要判断两个顶点是否具有连通性，只要判断它们的根节点是否为同一个节点即可。\n在「并查集」数据结构中，它的两个灵魂函数，分别是 find和 union。find 函数是为了找出给定顶点的根节点。 union 函数是通过更改顶点根节点的方式，将两个原本不相连接的顶点表示为两个连接的顶点。对于「并查集」来说，它还有一个重要的功能性函数 connected。它最主要的作用就是检查两个顶点的「连通性」。find 和 union 函数是「并查集」中必不可少的函数。connected 函数则需要根据题目的意思来决定是否需要。\n「并查集」代码基本结构 public class UnionFind { // UnionFind 的构造函数，size 为 root 数组的长度 public UnionFind(int size) {} public int find(int x) {} public void union(int x, int y) {} public boolean connected(int x, int y) {} } 「并查集」的 find 函数 它主要是用于查找顶点 x 的根结点。\n find 函数的基本实现  public int find(int x) { while (x != root[x]) { x = root[x]; } return x; }  find 函数的优化 - 路径压缩  public int find(int x) { if (x == root[x]) { return x; } return root[x] = find(root[x]); } 「并查集」的 union 函数 它主要是连接两个顶点 x 和 y 。将它们的根结点变成相同的，即代表它们来自于同一个根节点。\n union 函数的基本实现  public void union(int x, int y) { int rootX = find(x); int rootY = find(y); if (rootX != rootY) { root[rootY] = x; } };  union 函数的优化 - 按秩合并  public void union(int x, int y) { int rootX = find(x); int rootY = find(y); if (rootX != rootY) { if (rank[rootX] \u0026gt; rank[rootY]) { root[rootY] = rootX; } else if (rank[rootX] \u0026lt; rank[rootY]) { root[rootX] = rootY; } else { root[rootY] = rootX; rank[rootX] += 1; } } }; 「并查集」的 connected 函数 它主要是检查两个顶点 x 和 y 的「连通性」。这个函数通过顶点 x 和 y 的根结点是否相同来判断 x 和 y 的「连通性」。如果 x 和 y 的根结点相同，则为连通。反之，则为不连通。\npublic boolean connected(int x, int y) { return find(x) == find(y); } 「并查集」的刷题小技巧 「并查集」的代码是高度模版化的。所以作者建议大家熟记「并查集」的实现代码，这样小伙伴们在遇到「并查集」的算法题目的时候，就可以淡定的应对了。作者推荐大家在理解的前题下，请熟记「基于路径压缩+按秩合并的并查集」的实现代码。\n"});index.add({'id':41,'href':'/docs/kafka/6.kafka%E6%95%B0%E6%8D%AE%E6%A3%80%E7%B4%A2%E6%9C%BA%E5%88%B6/','title':"6.kafka数据检索机制",'content':"6.kafka数据检索机制   topic在物理层面以partition为分组，一个topic可以分成若干个partition partition还可以细分为Segment，一个partition物理上由多个Segment组成  segment 的参数有两个：  log.segment.bytes：单个segment可容纳的最大数据量，默认为1GB log.segment.ms：Kafka在commit一个未写满的segment前，所等待的时间（默认为7 天）     LogSegment 文件由两部分组成，分别为“.index”文件和“.log”文件，分别表示为 Segment 索引文 件和数据文件。  partition全局的第一个segment从0开始，后续每个segment文件名为上一个segment文件 最后一条消息的offset值 数值大小为64位，20位数字字符长度，没有数字用0填充 第一个segment 00000000000000000000.index 00000000000000000000.log 第二个segment，文件命名以第一个segment的最后一条消息的offset组成 00000000000000170410.index 00000000000000170410.log 第三个segment，文件命名以上一个segment的最后一条消息的offset组成 00000000000000239430.index 00000000000000239430.log    消息都具有固定的物理结构，包括：offset(8 Bytes)、消息体的大小(4 Bytes)、crc32(4 Bytes)、 magic(1 Byte)、attributes(1 Byte)、key length(4 Bytes)、key(K Bytes)、payload(N Bytes)等等 字段，可以确定一条消息的大小，即读取到哪里截止。    "});index.add({'id':42,'href':'/docs/algorithm/%E5%9B%BE/6.%E5%8D%95%E6%BA%90%E6%9C%80%E7%9F%AD%E8%B7%AF%E5%BE%84%E7%9B%B8%E5%85%B3%E7%AE%97%E6%B3%95/','title':"6.单源最短路径相关算法",'content':"6.单源最短路径相关算法 "});index.add({'id':43,'href':'/docs/algorithm/%E5%9B%BE/7.%E6%8B%93%E6%89%91%E6%8E%92%E5%BA%8F%E4%B9%8Bkahn%E7%AE%97%E6%B3%95/','title':"7.拓扑排序之Kahn算法",'content':"7.拓扑排序之Kahn算法 "});index.add({'id':44,'href':'/docs/kafka/7.%E6%95%B0%E6%8D%AE%E7%9A%84%E5%AE%89%E5%85%A8%E6%80%A7/','title':"7.数据的安全性",'content':"7.数据的安全性 producer delivery guarantee 0. At least one 消息绝不会丢，但可能会重复传输 1. At most once 消息可能会丢，但绝不会重复传输 2. Exactly once 每条消息肯定会被传输一次且仅传输一次  Producers可以选择是否为数据的写入接收ack，有以下几种ack的选项：request.required.acks  acks=0 * Producer 在 ISR 中的 Leader 已成功收到的数据并得到确认后发送下一条 Message。 acks=1 * 这意味着 Producer 无需等待来自 Broker 的确认而继续发送下一批消息。 acks=all * Producer 需要等待 ISR 中的所有 Follower 都确认接收到数据后才算一次发送完成，可 靠性最高。    ISR机制  关键词  AR : Assigned Replicas 用来标识副本的全集 OSR ： out -sync Replicas 离开同步队列的副本 ISR ： in -sync Replicas 加入同步队列的副本 ISR = Leader + 没有落后太多的副本;AR = OSR+ ISR。   我们备份数据就是防止数据丢失，当主节点挂掉时，可以启用备份节点  producer\u0026ndash;push\u0026ndash;\u0026gt;leader leader\u0026ndash;pull\u0026ndash;\u0026gt;follower Follower每间隔一定时间去Leader拉取数据，来保证数据的同步   ISR(in-syncReplica  当主节点挂点，并不是去Follower选择主，而是从ISR中选择主 判断标准  超过10秒钟没有同步数据  replica.lag.time.max.ms=10000   主副节点差4000条数据  rerplica.lag.max.messages=4000     脏节点选举  kafka采用一种降级措施来处理： 选举第一个恢复的node作为leader提供服务，以它的数据为基准，这个措施被称为脏 leader选举      broker数据存储机制  无论消息是否被消费，kafka 都会保留所有消息。有两种策略可以删除旧数据：  1. 基于时间：log.retention.hours=168 2. 基于大小：log.retention.bytes=1073741824 "});index.add({'id':45,'href':'/docs/docker/','title':"docker",'content':"Docker 1、概念  镜像：可以理解为软件安装包，可以方便的进行传播和安装。 容器：软件安装后的状态，每个软件运行环境都是独立的、隔离的，称之为容器。  1.1、安装 https://docs.docker.com/engine/install/#server\n1.2、镜像加速源    镜像加速器 镜像加速器地址     Docker 中国官方镜像 https://registry.docker-cn.com   DaoCloud 镜像站 http://f1361db2.m.daocloud.io   Azure 中国镜像 https://dockerhub.azk8s.cn   科大镜像站 https://docker.mirrors.ustc.edu.cn   阿里云 https://\u0026lt;your_code\u0026gt;.mirror.aliyuncs.com   七牛云 https://reg-mirror.qiniu.com   网易云 https://hub-mirror.c.163.com   腾讯云 https://mirror.ccs.tencentyun.com    通过:registry-mirrors参数配置\n2、Docker 快速安装软件 2.1、演示 Docker 安装 Redis Docker 官方镜像仓库查找 Redis ：https://hub.docker.com/\n安装: docker run -d -p 6379:6379 \u0026ndash;name redis redis:latest 3、命令参考 https://docs.docker.com/engine/reference/run/\n3.1、仓库相关    命令 描述     docker search $KEY_WORD 查找镜像   docker pull $REGISTRY:$TAG 获取镜像   docker push $IMAGE_NAME:$IMAGE_TAG 推送镜像到仓库，需要先登录   docker login $REGISTRY_URL 登录仓库   docker logout $REGISTRY_URL 退出仓库   docker info 显示Docker详细的系统信息，可查看仓库地址   docker version 显示Docker信息   docker \u0026ndash;help 显示Docker的帮助信息    3.2、容器相关    命令 描述     docker attach $CONTAINER_ID 启动一个已存在的docker容器   docker stop $CONTAINER_ID 停止docker容器   docker start $CONTAINER_ID 启动docker容器   docker restart $CONTAINER_ID 重启docker容器   docker kill $CONTAINER_ID 强制关闭docker容器   docker pause $CONTAINER_ID 暂停容器   docker unpause $CONTAINER_ID 恢复暂停的容器   docker rename $CONTAINER_ID 重新命名docker容器   docker rm $CONTAINER_ID 删除容器   docker logs $CONTAINER_ID 查看docker容器运行日志，确保正常运行   docker inspect $CONTAINER_ID 查看container的容器属性，比如ip等等   docker port $CONTAINER_ID 查看container的端口映射   docker top $CONTAINER_ID 查看容器中正在运行的进程   docker commit $CONTAINER_ID $NEW_IMAGE_NAME:$NEW_IMAGE_TAG 将容器保存为镜像   docker ps -a 查看所有容器   docker stats 查看容器的资源使用情况    3.3、镜像相关    命令 描述     docker images 查看本地镜像   docker rmi $IMAGE_ID 删除本地镜像   docker rmi -f $(docker images -qa) 删除本地所有镜像   docker inspect $IMAGE_ID 查看镜像详情   docker save $IMAGE_ID \u0026gt; 文件路径 保存镜像为离线文件   docker save -o 文件路径 $IMAGE_ID 保存镜像为离线文件   docker load \u0026lt; 文件路径 加载文件为docker镜像   docker load -i 文件路径 加载文件为docker镜像   docker tag $IMAGE_ID $NEW_IMAGE_NAME:$NEW_IMAGE_TAG 修改镜像TAG   docker run 参数 $IMAGE_ID $CMD 运行一个镜像   docker history $IMAGE_ID 显示镜像每层的变更内容    3.4、run命令相关    参数 描述     -d 后台运行容器, 并返回容器ID；不指定时, 启动后开始打印日志, Ctrl+C退出命令同时会关闭容器   -i 以交互模式运行容器, 通常与-t同时使用   -t 为容器重新分配一个伪输入终端, 通常与-i同时使用   \u0026ndash;name container_name 设置容器名称, 不指定时随机生成   -h container_hostname 设置容器的主机名, 默认随机生成   \u0026ndash;dns 8.8.8.8 指定容器使用的DNS服务器, 默认和宿主机一致   -e docker_host=172.17.0.1 设置环境变量   \u0026ndash;cpuset=\u0026quot;0-2\u0026rdquo; or \u0026ndash;cpuset=\u0026quot;0,1,2\u0026rdquo; 绑定容器到指定CPU运行   -m 100M 设置容器使用内存最大值   \u0026ndash;net bridge 指定容器的网络连接类型, 支持bridge/host/none/container四种类型   \u0026ndash;ip 172.18.0.13 为容器指定固定IP（需要使用自定义网络none）   \u0026ndash;expose 8081 \u0026ndash;expose 8082 开放一个端口或一组端口，会覆盖镜像设置中开放的端口   -p [宿主机端口]:[容器内端口] 宿主机到容器的端口映射，可指定宿主机的要监听的IP，默认为0.0.0.0   -P 注意是大写的, 宿主机随机指定一组可用的端口映射容器expose的所有端口   -v [宿主机目录路径]:[容器内目录路径] 挂载宿主机的指定目录（或文件）到容器内的指定目录（或文件）   \u0026ndash;add-host [主机名]:[IP] 为容器hosts文件追加host, 默认会在hosts文件最后追加[主机名]:[容器IP]   \u0026ndash;volumes-from [其他容器名] 将其他容器的数据卷添加到此容器   \u0026ndash;link [其他容器名]:[在该容器中的别名] 添加链接到另一个容器，在本容器hosts文件中加入关联容器的记录，效果类似于\u0026ndash;add-host    3.5、进入当前正在运行的容器 docker exec -it 容器id /bin/bash #进入容器开启新的终端 docker attach 容器id /bin/bash #进入容器正在执行的终端,不会启动新的进程\n3.6、从容器拷贝文件到主机 docker cp 容器id:容器内路径 目的的主机路径\n4、容器数据卷 4.1、使用数据卷 4.1.1、直接使用命令来挂载 -v  docker run -it -v [宿主机目录路径]:[容器内目录路径] centos /bin/bash docker inspect 容器id #查看Mounts 双向同步的,在容器中改，或者在宿主机改，都会互相同步的。  4.1.2、匿名挂载  -v 容器内路径: docker run -d -P -name nginx01 -v /etc/nginx nginx 查看所有卷的情况 docker volume ls  4.1.3、具名挂载  -v 卷名:容器内路径: docker run -d -P -name nginx02 -v juming-nginx:/etc/nginx nginx 查看一下这个卷 docker volume inspect 卷名  4.1.4、指定路径挂载  -v 宿主路径:容器内路径  4.1.5、扩展 docker run -d -P -name nginx02 -v juming-nginx:/etc/nginx:ro nginx #容器不能修改 ro: 只读, rw:可读写\n所有的docker容器内的卷,没有指定目录的情况下都是在 /var/lib/docker/volumes/xxxx/_data\n4.2、通过Dockerfile 参考5、Dockerfile\n4.3、数据卷容器 利用容器给别的容器共享数据\ndocker run -it \u0026ndash;name docker01 [容器名称/id]\ndocker run -it \u0026ndash;name docker02 \u0026ndash;volumes-from docker01 [容器名称/id]\n5、Dockerfile Dockerfile是用来构建docker镜像文件\n5.1、构建步骤  编写一个dockerfile文件 docker build 构建成一个镜像 docker run 运行镜像 docker push 发布镜像(DockerHub、阿里云镜像仓库)  5.2、Dockerfile的指令 FROM #基础镜像,一切从这里开始构建 MAINTAINER #镜像是谁写的, 姓名+邮箱 RUN #镜像构建的时候需要运行的命令 ADD #步骤,tocat镜像；添加内容 WORKDIR #镜像的工作目录 VOLUME #挂载的目录位置 EXPOSE #暴露端口 CMD #指定这个容器启动的时候要运行的命令，只有最后一个会生效，可被替代 ENTRYPOINT #指定这个容器启动的时候要运行的命令,可以追加命令 ONBUILD #当构建一个被继承DockerFile 这个时候就会运行ONBUILD的指令、触发指令 COPY #类似ADD，将我们文件拷贝到镜像中 ENV #构建的时候设置环境变量 5.3、实战 scratch 最基础镜像\n5.3.1、编写dockerfile文件 FROM centos MAINTAINER mrc\u0026lt;mrc@qq.com\u0026gt; ENV MYPATH /usr/local WORKDIR $MYPATH RUN yum -y install vim RUN yum -y install net-tools EXPOSE 80 CMD echo $MYPATH CMD echo \u0026quot;----end----\u0026quot; CMD /bin/bash 5.3.2、构建 docker build -f dockerfile文件路径 -t 镜像名:[tag] .\n5.4、研究人家dockerfile如何做的 docker history 镜像id\n5.5、CMD和ENTRYPOINT 区别 CMD #指定这个容器启动的时候要运行的命令，只有最后一个会生效，可被替代 ENTRYPOINT #指定这个容器启动的时候要运行的命令,可以追加命令\n5.6、发布自己的镜像 git push [容器名]:[版本号]\n6、Docker网络 6.1、原理 我们每启动一个docker容器 docker就会给docker容器分配一个ip,我们只要安装了docker，就会有一个网卡docker0\n桥接模式，使用的技术是evth-pair技术\n我们发现这个容器带来的网卡，都是一对对的 evth-pair 就是一对虚拟设备接口，他们都是成对出现的，一段俩这协议，一段彼此相连 正以为有这个特性，evth-pair充当了桥梁，连接各种虚拟网络设备的 openstac docker容器之间的连接，都是使用evth-pair技术 容器和容器之间是可以互相ping通的\n6.2、\u0026ndash;link 思考一个场景，我们编写了一个微服务,database url=ip 项目不重启，数据库ip换掉了，我们希望可以处理这个问题。可以名字来进行访问吗？\ndocker run -d -P -name tomcat03 \u0026ndash;link tomcat02 tomcat\ndocker exec -it tomcate ping tomcate02\n6.3、自定义网络 6.3.1、网络模式  bridge: 桥接docker （默认,自己创建也使用bridge模式） none: 不配置网络 host: 和宿主机共享网络 container: 容器网络连通 (用的少,局限很大)  #我们直接启动的命令 --net 吧 ridge， 而这个就是我们的docker0 docker run -d -P --name tomcat01 --net bridge tomcat # docker0特点, 默认，域名不能访问, --link可以打通连接 # 我们可以自定义一个网络 # --driver bridge # --subnet 192.168.0.0/16 192.168.0.0/24 # --gateway 192.168.0.1 docker network create --driver bridge --subnet 192.168.0.0、16 --gateway --gateway 192.168.0.1 mynet 我们自定义的网络docker都已经帮我们维护好了对应的关系，推荐我们平时这样使用网络\n6.3.2、网络连通 docker network connect mynet tomcat01\n7、redis集群部署实战 // todo::\n8、微服务打包docker镜像 9、Docker compose 10、Docker Swarm 11、CICD "});index.add({'id':46,'href':'/docs/jiagou/','title':"jiagou",'content':"架构 "});index.add({'id':47,'href':'/docs/vbox/','title':"vbox",'content':"vbox vbox常用到的一些配置\n"});index.add({'id':48,'href':'/docs/algorithm/%E5%9B%BE/5.%E6%9C%80%E5%B0%8F%E7%94%9F%E6%88%90%E6%A0%91%E7%9B%B8%E5%85%B3%E7%AE%97%E6%B3%95/5.1.%E5%88%87%E5%88%86%E5%AE%9A%E7%90%86/','title':"5.1.切分定理",'content':""});index.add({'id':49,'href':'/docs/algorithm/%E5%9B%BE/5.%E6%9C%80%E5%B0%8F%E7%94%9F%E6%88%90%E6%A0%91%E7%9B%B8%E5%85%B3%E7%AE%97%E6%B3%95/5.2.kruskal%E7%AE%97%E6%B3%95/','title':"5.2. Kruskal算法",'content':""});index.add({'id':50,'href':'/docs/algorithm/%E5%9B%BE/5.%E6%9C%80%E5%B0%8F%E7%94%9F%E6%88%90%E6%A0%91%E7%9B%B8%E5%85%B3%E7%AE%97%E6%B3%95/5.3.prim%E7%AE%97%E6%B3%95/','title':"5.3. Prim算法",'content':""});index.add({'id':51,'href':'/docs/go/%E5%AE%89%E8%A3%85/','title':"安装",'content':"安装 卸载docker sudo yum remove docker\ndocker-client\ndocker-client-latest\ndocker-common\ndocker-latest\ndocker-latest-logrotate\ndocker-logrotate\ndocker-engine\n安装docker环境依赖 yum install -y yum-utils device-mapper-persistent-data lvm2\n配置国内docker-ce的yum源(阿里云) yum-config-manager \u0026ndash;add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo\n会下载 /etc/yum.repos.d/docker-ce.repo 文件\n安装docker yum install aocker-ce docker-ce-cli containerd.io -y\ndocker-ce-cli docker命令行工具包 containerd.io 容器接口相关包 启动并设置开机启动 systemctl start docker \u0026amp;\u0026amp; systemctl enable docker\ncurl -fsSL get.docker.com -o get-docker.sh\n"});index.add({'id':52,'href':'/docs/redis/%E7%BC%93%E5%AD%98/%E7%BC%93%E5%AD%98%E7%A9%BF%E9%80%8F/','title':"缓存穿透",'content':""});index.add({'id':53,'href':'/posts/','title':"Posts",'content':""});index.add({'id':54,'href':'/docs/','title':"Docs",'content':""});index.add({'id':55,'href':'/docs/notices/','title':"成\"神\"之路",'content':""});})();